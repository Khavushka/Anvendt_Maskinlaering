{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise - MNIST\n",
    "\n",
    "1. Use the $\\texttt{mnist}$ dataset (as just shown in the slides). Build a neural network using what we have explored so far and evaluate its performance on the test data.\n",
    "1. Explore whether your neural network appears to be under- or overfitting by constructing plots of the train and test losses and accuracies during training. Use this information to improve your model - that is, train for longer if it appears to be underfitting and shorter if it appears to be overfitting. Does your test performance improve? What about your train performance?\n",
    "1. (Bonus): Later during the semester, we will explore *convolutional neural networks*. For those of you finished with (1) and (2), you may try this now to improve your model; check https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D for details.\n",
    "\n",
    "**See slides for more details!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1\n",
    "\n",
    "Use the $\\texttt{mnist}$ dataset (as just shown in the slides). Build a neural network using what we have explored so far and evaluate its performance on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,) (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Scale your features in some fashion (otherwise performance will likely suffer)\n",
    "x_train = x_train/255 \n",
    "x_test = x_test/255\n",
    "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max =1.0\n",
      "min =0.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(f'max ={np.max(x_train)}')\n",
    "print(f'min ={np.min(x_train)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a model to get you started.\n",
    "\n",
    "Take note of the \"Flatten\" layer. This is important to reshape your data from (28, 28) to (784,).\n",
    "\n",
    "Alternatively, you could reshape your data (the x's). This can be done using:\n",
    "\n",
    "$\\texttt{x = x.reshape(n, 784)}$ \n",
    "\n",
    "where $n$ is the number of samples (60k for training, 10k for test).\n",
    "\n",
    "Then you don't need the Flatten layer, but remember to still specify an input shape of your first layer (i.e. 784 if you have done this reshaping).\n",
    "\n",
    "**Note**: Do feel free to experiment with the number of layers, nodes per layer, and optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               200960    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                2570      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 269,322\n",
      "Trainable params: 269,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# model = tf.keras.models.Sequential([\n",
    "#     # input shape required in the first layer\n",
    "#     tf.keras.layers.Flatten(64, activation=\"relu\", input_shape=(28, 28)),\n",
    "#     # map 64 TO 256 features and applu ReLU\n",
    "#     tf.keras.layers.Dense(256, activation='relu'),\n",
    "#     tf.keras.layers.Dense(256, activation='relu'),\n",
    "#     # softmax is used for classification\n",
    "#     tf.keras.layers.Dense(10, activation='softmax'),\n",
    "# ])\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax'),\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "235/235 [==============================] - 3s 9ms/step - loss: 0.3183 - accuracy: 0.9100 - val_loss: 0.1430 - val_accuracy: 0.9558\n",
      "Epoch 2/50\n",
      "235/235 [==============================] - 3s 13ms/step - loss: 0.1168 - accuracy: 0.9652 - val_loss: 0.0982 - val_accuracy: 0.9700\n",
      "Epoch 3/50\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 0.0785 - accuracy: 0.9763 - val_loss: 0.0881 - val_accuracy: 0.9728\n",
      "Epoch 4/50\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.0564 - accuracy: 0.9828 - val_loss: 0.0782 - val_accuracy: 0.9763\n",
      "Epoch 5/50\n",
      "235/235 [==============================] - 3s 13ms/step - loss: 0.0421 - accuracy: 0.9870 - val_loss: 0.0730 - val_accuracy: 0.9778\n",
      "Epoch 6/50\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 0.0302 - accuracy: 0.9908 - val_loss: 0.0698 - val_accuracy: 0.9793\n",
      "Epoch 7/50\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0243 - accuracy: 0.9923 - val_loss: 0.0676 - val_accuracy: 0.9796\n",
      "Epoch 8/50\n",
      "235/235 [==============================] - 2s 11ms/step - loss: 0.0181 - accuracy: 0.9944 - val_loss: 0.0746 - val_accuracy: 0.9796\n",
      "Epoch 9/50\n",
      "235/235 [==============================] - 2s 11ms/step - loss: 0.0145 - accuracy: 0.9958 - val_loss: 0.0696 - val_accuracy: 0.9803\n",
      "Epoch 10/50\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0110 - accuracy: 0.9969 - val_loss: 0.0776 - val_accuracy: 0.9789\n",
      "Epoch 11/50\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0116 - accuracy: 0.9965 - val_loss: 0.0861 - val_accuracy: 0.9766\n",
      "Epoch 12/50\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0091 - accuracy: 0.9971 - val_loss: 0.0756 - val_accuracy: 0.9800\n",
      "Epoch 13/50\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0057 - accuracy: 0.9984 - val_loss: 0.0760 - val_accuracy: 0.9797\n",
      "Epoch 14/50\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0037 - accuracy: 0.9991 - val_loss: 0.0805 - val_accuracy: 0.9811\n",
      "Epoch 15/50\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.0070 - accuracy: 0.9979 - val_loss: 0.0857 - val_accuracy: 0.9788\n",
      "Epoch 16/50\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0125 - accuracy: 0.9958 - val_loss: 0.0996 - val_accuracy: 0.9765\n",
      "Epoch 17/50\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0120 - accuracy: 0.9954 - val_loss: 0.0854 - val_accuracy: 0.9789\n",
      "Epoch 18/50\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 0.0050 - accuracy: 0.9982 - val_loss: 0.0879 - val_accuracy: 0.9793\n",
      "Epoch 19/50\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0079 - accuracy: 0.9974 - val_loss: 0.0932 - val_accuracy: 0.9799\n",
      "Epoch 20/50\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.0817 - val_accuracy: 0.9835\n",
      "Epoch 21/50\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 6.8135e-04 - accuracy: 0.9999 - val_loss: 0.0857 - val_accuracy: 0.9825\n",
      "Epoch 22/50\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 2.4468e-04 - accuracy: 1.0000 - val_loss: 0.0837 - val_accuracy: 0.9836\n",
      "Epoch 23/50\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 1.1199e-04 - accuracy: 1.0000 - val_loss: 0.0846 - val_accuracy: 0.9836\n",
      "Epoch 24/50\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 8.6678e-05 - accuracy: 1.0000 - val_loss: 0.0855 - val_accuracy: 0.9835\n",
      "Epoch 25/50\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 7.3142e-05 - accuracy: 1.0000 - val_loss: 0.0860 - val_accuracy: 0.9835\n",
      "Epoch 26/50\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 6.3631e-05 - accuracy: 1.0000 - val_loss: 0.0875 - val_accuracy: 0.9841\n",
      "Epoch 27/50\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 5.5447e-05 - accuracy: 1.0000 - val_loss: 0.0883 - val_accuracy: 0.9837\n",
      "Epoch 28/50\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 5.0249e-05 - accuracy: 1.0000 - val_loss: 0.0892 - val_accuracy: 0.9839\n",
      "Epoch 29/50\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 4.4255e-05 - accuracy: 1.0000 - val_loss: 0.0898 - val_accuracy: 0.9840\n",
      "Epoch 30/50\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 3.9908e-05 - accuracy: 1.0000 - val_loss: 0.0908 - val_accuracy: 0.9844\n",
      "Epoch 31/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 3.5732e-05 - accuracy: 1.0000 - val_loss: 0.0915 - val_accuracy: 0.9840\n",
      "Epoch 32/50\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 3.1973e-05 - accuracy: 1.0000 - val_loss: 0.0923 - val_accuracy: 0.9841\n",
      "Epoch 33/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 2.8518e-05 - accuracy: 1.0000 - val_loss: 0.0931 - val_accuracy: 0.9842\n",
      "Epoch 34/50\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 2.5748e-05 - accuracy: 1.0000 - val_loss: 0.0940 - val_accuracy: 0.9842\n",
      "Epoch 35/50\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 2.3499e-05 - accuracy: 1.0000 - val_loss: 0.0943 - val_accuracy: 0.9842\n",
      "Epoch 36/50\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 2.1043e-05 - accuracy: 1.0000 - val_loss: 0.0950 - val_accuracy: 0.9844\n",
      "Epoch 37/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 1.9188e-05 - accuracy: 1.0000 - val_loss: 0.0963 - val_accuracy: 0.9841\n",
      "Epoch 38/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 1.6895e-05 - accuracy: 1.0000 - val_loss: 0.0974 - val_accuracy: 0.9840\n",
      "Epoch 39/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 1.5756e-05 - accuracy: 1.0000 - val_loss: 0.0980 - val_accuracy: 0.9841\n",
      "Epoch 40/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 1.3909e-05 - accuracy: 1.0000 - val_loss: 0.0990 - val_accuracy: 0.9839\n",
      "Epoch 41/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 1.2608e-05 - accuracy: 1.0000 - val_loss: 0.0994 - val_accuracy: 0.9843\n",
      "Epoch 42/50\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 1.0986e-05 - accuracy: 1.0000 - val_loss: 0.1005 - val_accuracy: 0.9839\n",
      "Epoch 43/50\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 1.0068e-05 - accuracy: 1.0000 - val_loss: 0.1005 - val_accuracy: 0.9843\n",
      "Epoch 44/50\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 8.9291e-06 - accuracy: 1.0000 - val_loss: 0.1021 - val_accuracy: 0.9841\n",
      "Epoch 45/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 8.0570e-06 - accuracy: 1.0000 - val_loss: 0.1021 - val_accuracy: 0.9842\n",
      "Epoch 46/50\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 7.3833e-06 - accuracy: 1.0000 - val_loss: 0.1036 - val_accuracy: 0.9841\n",
      "Epoch 47/50\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 6.5079e-06 - accuracy: 1.0000 - val_loss: 0.1045 - val_accuracy: 0.9838\n",
      "Epoch 48/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 5.8664e-06 - accuracy: 1.0000 - val_loss: 0.1050 - val_accuracy: 0.9838\n",
      "Epoch 49/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 5.1561e-06 - accuracy: 1.0000 - val_loss: 0.1061 - val_accuracy: 0.9838\n",
      "Epoch 50/50\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 4.5749e-06 - accuracy: 1.0000 - val_loss: 0.1067 - val_accuracy: 0.9838\n",
      "{'loss': [0.3182752728462219, 0.11683066934347153, 0.07852523773908615, 0.05637459456920624, 0.04212328419089317, 0.030169466510415077, 0.0242741908878088, 0.018057262524962425, 0.01445805560797453, 0.011035553179681301, 0.011563817039132118, 0.009140495210886002, 0.005676384083926678, 0.0036794873885810375, 0.00699708703905344, 0.012488169595599174, 0.011965210549533367, 0.0049913316033780575, 0.007866451516747475, 0.0023814071901142597, 0.0006813541986048222, 0.0002446786093059927, 0.00011199494474567473, 8.667761721881106e-05, 7.314220420084894e-05, 6.363051215885207e-05, 5.5446562328143045e-05, 5.0249305786564946e-05, 4.4255426473682746e-05, 3.9907823520479724e-05, 3.5731853131437674e-05, 3.197258774889633e-05, 2.8517872124211863e-05, 2.5748227926669642e-05, 2.349887290620245e-05, 2.1043377273599617e-05, 1.9187596990377642e-05, 1.6894677173695527e-05, 1.575594251335133e-05, 1.3909206245443784e-05, 1.2607780263351742e-05, 1.0986039342242293e-05, 1.0068443771160673e-05, 8.929133400670253e-06, 8.057021659624297e-06, 7.383298907370772e-06, 6.507922535092803e-06, 5.86644728173269e-06, 5.15606916451361e-06, 4.574866125039989e-06], 'accuracy': [0.910016655921936, 0.9651666879653931, 0.9763166904449463, 0.9828166961669922, 0.9869666695594788, 0.9908166527748108, 0.9922833442687988, 0.9944000244140625, 0.9958000183105469, 0.9968833327293396, 0.9964500069618225, 0.997083306312561, 0.9983500242233276, 0.9990833401679993, 0.997866690158844, 0.9958166480064392, 0.9954166412353516, 0.9982166886329651, 0.9974333047866821, 0.9994000196456909, 0.999916672706604, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'val_loss': [0.14297650754451752, 0.09816121309995651, 0.08812457323074341, 0.07818295806646347, 0.07301768660545349, 0.06980128586292267, 0.06761893630027771, 0.07464173436164856, 0.06958875805139542, 0.07757017761468887, 0.08613250404596329, 0.07564398646354675, 0.075991690158844, 0.0805402547121048, 0.08569153398275375, 0.0996377244591713, 0.0854419469833374, 0.08787985891103745, 0.09316558390855789, 0.08171255886554718, 0.08573901653289795, 0.0836826041340828, 0.08464416861534119, 0.08553097397089005, 0.08602490276098251, 0.08753956854343414, 0.088284932076931, 0.0891900584101677, 0.08982959389686584, 0.09078893065452576, 0.09149549901485443, 0.09234544634819031, 0.09308760613203049, 0.09398019313812256, 0.09428834170103073, 0.09500663727521896, 0.0962926372885704, 0.09740142524242401, 0.09796371310949326, 0.09902425855398178, 0.09941872954368591, 0.10051976889371872, 0.10051809996366501, 0.1020965725183487, 0.10212114453315735, 0.10357286036014557, 0.10445322096347809, 0.10499155521392822, 0.10613876581192017, 0.10670601576566696], 'val_accuracy': [0.9557999968528748, 0.9700000286102295, 0.9728000164031982, 0.9763000011444092, 0.9778000116348267, 0.9793000221252441, 0.9796000123023987, 0.9796000123023987, 0.9803000092506409, 0.9789000153541565, 0.9765999913215637, 0.9800000190734863, 0.9797000288963318, 0.9811000227928162, 0.9787999987602234, 0.9764999747276306, 0.9789000153541565, 0.9793000221252441, 0.9799000024795532, 0.9835000038146973, 0.9825000166893005, 0.9836000204086304, 0.9836000204086304, 0.9835000038146973, 0.9835000038146973, 0.9840999841690063, 0.9836999773979187, 0.9839000105857849, 0.984000027179718, 0.9843999743461609, 0.984000027179718, 0.9840999841690063, 0.9842000007629395, 0.9842000007629395, 0.9842000007629395, 0.9843999743461609, 0.9840999841690063, 0.984000027179718, 0.9840999841690063, 0.9839000105857849, 0.9843000173568726, 0.9839000105857849, 0.9843000173568726, 0.9840999841690063, 0.9842000007629395, 0.9840999841690063, 0.9837999939918518, 0.9837999939918518, 0.9837999939918518, 0.9837999939918518]}\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(x_train,\n",
    "                    y_train,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    epochs=50,\n",
    "                    batch_size=256,\n",
    "                    verbose=1)\n",
    "\n",
    "print(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1067 - accuracy: 0.9838\n",
      "Test Loss: 0.1067\n",
      "Test Accuracy: 0.9838\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
    "print(f'Test Loss: {test_loss:.4f}')\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a small function you can use as a starting point for your network - but feel free to experiment!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2\n",
    "\n",
    "Explore whether your neural network appears to be under- or overfitting by constructing plots of the train and test losses and accuracies during training. Use this information to improve your model - that is, train for longer if it appears to be underfitting and shorter if it appears to be overfitting. Does your test performance improve? What about your train performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 4)         40        \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 24, 24, 8)         296       \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 22, 22, 8)         584       \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 3872)              0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 10)                38730     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 39,650\n",
      "Trainable params: 39,650\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 35s 18ms/step - loss: 0.1808 - accuracy: 0.9469 - val_loss: 0.0902 - val_accuracy: 0.9739\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 34s 18ms/step - loss: 0.0672 - accuracy: 0.9798 - val_loss: 0.0550 - val_accuracy: 0.9821\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 31s 17ms/step - loss: 0.0496 - accuracy: 0.9848 - val_loss: 0.0528 - val_accuracy: 0.9835\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 32s 17ms/step - loss: 0.0393 - accuracy: 0.9876 - val_loss: 0.0501 - val_accuracy: 0.9842\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 31s 16ms/step - loss: 0.0308 - accuracy: 0.9904 - val_loss: 0.0462 - val_accuracy: 0.9869\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.0462 - accuracy: 0.9869\n",
      "Test Loss (CNN): 0.0462\n",
      "Test Accuracy (CNN): 0.9869\n"
     ]
    }
   ],
   "source": [
    "# Reshape to additional dimension for single-channel image representation\n",
    "x_train = x_train.reshape(*x_train.shape[:3], 1)\n",
    "x_test = x_test.reshape(*x_test.shape[:3], 1)\n",
    "\n",
    "# Build a simple convolutional neural network (CNN)\n",
    "model_cnn = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(filters=4, kernel_size=3, activation='relu', input_shape=(28, 28, 1)),\n",
    "    tf.keras.layers.Conv2D(filters=8, kernel_size=3, activation='relu'),\n",
    "    tf.keras.layers.Conv2D(filters=8, kernel_size=3, activation='relu'),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(10, activation='softmax'),\n",
    "])\n",
    "\n",
    "model_cnn.summary()\n",
    "\n",
    "model_cnn.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "# Train the CNN\n",
    "model_cnn.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test))\n",
    "\n",
    "# Evaluate the CNN on the test set\n",
    "test_loss_cnn, test_accuracy_cnn = model_cnn.evaluate(x_test, y_test)\n",
    "print(f'Test Loss (CNN): {test_loss_cnn:.4f}')\n",
    "print(f'Test Accuracy (CNN): {test_accuracy_cnn:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exericse 3\n",
    "\n",
    "Later during the semester, we will explore *convolutional neural networks*. For those of you finished with (1) and (2), you may try this now to improve your model; check https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 26, 26, 4)         40        \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 24, 24, 8)         296       \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 22, 22, 8)         584       \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 3872)              0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 10)                38730     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 39,650\n",
      "Trainable params: 39,650\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "235/235 [==============================] - 30s 123ms/step - loss: 0.4064 - accuracy: 0.8874 - val_loss: 0.1178 - val_accuracy: 0.9650\n",
      "Epoch 2/50\n",
      "235/235 [==============================] - 28s 120ms/step - loss: 0.0965 - accuracy: 0.9709 - val_loss: 0.0711 - val_accuracy: 0.9783\n",
      "Epoch 3/50\n",
      "235/235 [==============================] - 25s 105ms/step - loss: 0.0735 - accuracy: 0.9783 - val_loss: 0.0654 - val_accuracy: 0.9813\n",
      "Epoch 4/50\n",
      "235/235 [==============================] - 26s 109ms/step - loss: 0.0618 - accuracy: 0.9813 - val_loss: 0.0645 - val_accuracy: 0.9796\n",
      "Epoch 5/50\n",
      "235/235 [==============================] - 26s 112ms/step - loss: 0.0551 - accuracy: 0.9837 - val_loss: 0.0543 - val_accuracy: 0.9836\n",
      "Epoch 6/50\n",
      "235/235 [==============================] - 23s 99ms/step - loss: 0.0480 - accuracy: 0.9851 - val_loss: 0.0597 - val_accuracy: 0.9820\n",
      "Epoch 7/50\n",
      "235/235 [==============================] - 26s 109ms/step - loss: 0.0428 - accuracy: 0.9866 - val_loss: 0.0593 - val_accuracy: 0.9825\n",
      "Epoch 8/50\n",
      "235/235 [==============================] - 25s 106ms/step - loss: 0.0398 - accuracy: 0.9876 - val_loss: 0.0600 - val_accuracy: 0.9836\n",
      "Epoch 9/50\n",
      "235/235 [==============================] - 24s 101ms/step - loss: 0.0346 - accuracy: 0.9894 - val_loss: 0.0575 - val_accuracy: 0.9831\n",
      "Epoch 10/50\n",
      "235/235 [==============================] - 24s 101ms/step - loss: 0.0314 - accuracy: 0.9903 - val_loss: 0.0538 - val_accuracy: 0.9846\n",
      "Epoch 11/50\n",
      "235/235 [==============================] - 24s 103ms/step - loss: 0.0289 - accuracy: 0.9906 - val_loss: 0.0516 - val_accuracy: 0.9852\n",
      "Epoch 12/50\n",
      "235/235 [==============================] - 25s 104ms/step - loss: 0.0264 - accuracy: 0.9914 - val_loss: 0.0518 - val_accuracy: 0.9859\n",
      "Epoch 13/50\n",
      "235/235 [==============================] - 24s 101ms/step - loss: 0.0240 - accuracy: 0.9924 - val_loss: 0.0591 - val_accuracy: 0.9839\n",
      "Epoch 14/50\n",
      "235/235 [==============================] - 24s 101ms/step - loss: 0.0215 - accuracy: 0.9932 - val_loss: 0.0583 - val_accuracy: 0.9846\n",
      "Epoch 15/50\n",
      "235/235 [==============================] - 27s 114ms/step - loss: 0.0211 - accuracy: 0.9931 - val_loss: 0.0637 - val_accuracy: 0.9842\n",
      "Epoch 16/50\n",
      "235/235 [==============================] - 29s 125ms/step - loss: 0.0178 - accuracy: 0.9944 - val_loss: 0.0563 - val_accuracy: 0.9856\n",
      "Epoch 17/50\n",
      "235/235 [==============================] - 24s 103ms/step - loss: 0.0158 - accuracy: 0.9952 - val_loss: 0.0599 - val_accuracy: 0.9861\n",
      "Epoch 18/50\n",
      "235/235 [==============================] - 23s 98ms/step - loss: 0.0147 - accuracy: 0.9953 - val_loss: 0.0585 - val_accuracy: 0.9857\n",
      "Epoch 19/50\n",
      "235/235 [==============================] - 23s 98ms/step - loss: 0.0133 - accuracy: 0.9959 - val_loss: 0.0638 - val_accuracy: 0.9857\n",
      "Epoch 20/50\n",
      "235/235 [==============================] - 23s 98ms/step - loss: 0.0127 - accuracy: 0.9960 - val_loss: 0.0700 - val_accuracy: 0.9849\n",
      "Epoch 21/50\n",
      "235/235 [==============================] - 23s 97ms/step - loss: 0.0116 - accuracy: 0.9962 - val_loss: 0.0704 - val_accuracy: 0.9843\n",
      "Epoch 22/50\n",
      "235/235 [==============================] - 24s 103ms/step - loss: 0.0096 - accuracy: 0.9970 - val_loss: 0.0685 - val_accuracy: 0.9857\n",
      "Epoch 23/50\n",
      "235/235 [==============================] - 27s 114ms/step - loss: 0.0094 - accuracy: 0.9969 - val_loss: 0.0753 - val_accuracy: 0.9839\n",
      "Epoch 24/50\n",
      "235/235 [==============================] - 34s 145ms/step - loss: 0.0080 - accuracy: 0.9975 - val_loss: 0.0829 - val_accuracy: 0.9836\n",
      "Epoch 25/50\n",
      "235/235 [==============================] - 29s 123ms/step - loss: 0.0065 - accuracy: 0.9980 - val_loss: 0.0726 - val_accuracy: 0.9848\n",
      "Epoch 26/50\n",
      "235/235 [==============================] - 24s 100ms/step - loss: 0.0075 - accuracy: 0.9975 - val_loss: 0.0780 - val_accuracy: 0.9841\n",
      "Epoch 27/50\n",
      "235/235 [==============================] - 25s 108ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.0835 - val_accuracy: 0.9852\n",
      "Epoch 28/50\n",
      "235/235 [==============================] - 25s 107ms/step - loss: 0.0067 - accuracy: 0.9980 - val_loss: 0.0972 - val_accuracy: 0.9832\n",
      "Epoch 29/50\n",
      "235/235 [==============================] - 26s 111ms/step - loss: 0.0058 - accuracy: 0.9980 - val_loss: 0.0901 - val_accuracy: 0.9841\n",
      "Epoch 30/50\n",
      "235/235 [==============================] - 24s 103ms/step - loss: 0.0058 - accuracy: 0.9981 - val_loss: 0.0848 - val_accuracy: 0.9853\n",
      "Epoch 31/50\n",
      "235/235 [==============================] - 29s 122ms/step - loss: 0.0052 - accuracy: 0.9983 - val_loss: 0.0926 - val_accuracy: 0.9841\n",
      "Epoch 32/50\n",
      "235/235 [==============================] - 23s 98ms/step - loss: 0.0036 - accuracy: 0.9989 - val_loss: 0.0837 - val_accuracy: 0.9851\n",
      "Epoch 33/50\n",
      "235/235 [==============================] - 23s 97ms/step - loss: 0.0021 - accuracy: 0.9996 - val_loss: 0.0961 - val_accuracy: 0.9864\n",
      "Epoch 34/50\n",
      "235/235 [==============================] - 23s 97ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.0907 - val_accuracy: 0.9857\n",
      "Epoch 35/50\n",
      "235/235 [==============================] - 21s 88ms/step - loss: 8.9623e-04 - accuracy: 0.9999 - val_loss: 0.0976 - val_accuracy: 0.9859\n",
      "Epoch 36/50\n",
      "235/235 [==============================] - 23s 99ms/step - loss: 0.0053 - accuracy: 0.9981 - val_loss: 0.1092 - val_accuracy: 0.9812\n",
      "Epoch 37/50\n",
      "235/235 [==============================] - 22s 95ms/step - loss: 0.0117 - accuracy: 0.9960 - val_loss: 0.1113 - val_accuracy: 0.9829\n",
      "Epoch 38/50\n",
      "235/235 [==============================] - 26s 110ms/step - loss: 0.0044 - accuracy: 0.9985 - val_loss: 0.1019 - val_accuracy: 0.9842\n",
      "Epoch 39/50\n",
      "235/235 [==============================] - 28s 117ms/step - loss: 0.0032 - accuracy: 0.9990 - val_loss: 0.0967 - val_accuracy: 0.9860\n",
      "Epoch 40/50\n",
      "235/235 [==============================] - 25s 106ms/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 0.1002 - val_accuracy: 0.9854\n",
      "Epoch 41/50\n",
      "235/235 [==============================] - 1227s 5s/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.1086 - val_accuracy: 0.9847\n",
      "Epoch 42/50\n",
      "235/235 [==============================] - 21s 89ms/step - loss: 9.0179e-04 - accuracy: 0.9998 - val_loss: 0.1079 - val_accuracy: 0.9850\n",
      "Epoch 43/50\n",
      "235/235 [==============================] - 23s 97ms/step - loss: 3.2356e-04 - accuracy: 1.0000 - val_loss: 0.1042 - val_accuracy: 0.9863\n",
      "Epoch 44/50\n",
      "235/235 [==============================] - 23s 100ms/step - loss: 1.6742e-04 - accuracy: 1.0000 - val_loss: 0.1066 - val_accuracy: 0.9862\n",
      "Epoch 45/50\n",
      "235/235 [==============================] - 23s 100ms/step - loss: 1.1863e-04 - accuracy: 1.0000 - val_loss: 0.1091 - val_accuracy: 0.9865\n",
      "Epoch 46/50\n",
      "235/235 [==============================] - 21s 91ms/step - loss: 9.0562e-05 - accuracy: 1.0000 - val_loss: 0.1105 - val_accuracy: 0.9870\n",
      "Epoch 47/50\n",
      "235/235 [==============================] - 21s 91ms/step - loss: 7.7938e-05 - accuracy: 1.0000 - val_loss: 0.1121 - val_accuracy: 0.9866\n",
      "Epoch 48/50\n",
      "235/235 [==============================] - 23s 98ms/step - loss: 6.9006e-05 - accuracy: 1.0000 - val_loss: 0.1144 - val_accuracy: 0.9868\n",
      "Epoch 49/50\n",
      "235/235 [==============================] - 23s 98ms/step - loss: 6.0985e-05 - accuracy: 1.0000 - val_loss: 0.1153 - val_accuracy: 0.9869\n",
      "Epoch 50/50\n",
      "235/235 [==============================] - 27s 116ms/step - loss: 5.3330e-05 - accuracy: 1.0000 - val_loss: 0.1171 - val_accuracy: 0.9867\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.1171 - accuracy: 0.9867\n",
      "Test Loss (CNN): 0.0462\n",
      "Test Accuracy (CNN): 0.9869\n"
     ]
    }
   ],
   "source": [
    "# To get you started \n",
    "\n",
    "# Reshape to additional dimension for single-channel image representation\n",
    "x_train = x_train.reshape(*x_train.shape[:3], 1)\n",
    "x_test = x_test.reshape(*x_test.shape[:3], 1)\n",
    "\n",
    "# An example model\n",
    "model_cnn = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(filters=4, kernel_size=3, activation='relu', input_shape=(28, 28, 1)),\n",
    "    tf.keras.layers.Conv2D(filters=8, kernel_size=3, activation='relu'),\n",
    "    tf.keras.layers.Conv2D(filters=8, kernel_size=3, activation='relu'),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(10, activation='softmax'),\n",
    "])\n",
    "\n",
    "model_cnn.summary()\n",
    "\n",
    "model_cnn.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics='accuracy',\n",
    ")\n",
    "\n",
    "model_cnn.fit(x_train,\n",
    "                    y_train,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    epochs=50,\n",
    "                    batch_size=256,\n",
    "                    verbose=1)\n",
    "\n",
    "model_cnn.evaluate(x_test, y_test)\n",
    "print(f'Test Loss (CNN): {test_loss_cnn:.4f}')\n",
    "print(f'Test Accuracy (CNN): {test_accuracy_cnn:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('amlfall22')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "d3cedec8935a2c28d6fd602c3007747750e2af1c4c937c29fac0d323bf1b544b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
