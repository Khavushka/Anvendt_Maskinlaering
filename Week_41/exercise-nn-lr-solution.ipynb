{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise - learning rate and batch size\n",
    "\n",
    "1. Consider last exercise (i.e. the MNIST data). Suppose you are restricted to **training for only 2 epochs** but still want a good model. You recognize that finding the right learning rate is going to be very important. For this reason, you split your training data into a train and a validation set and use the validation set to find the optimal learning rate. Train a model with you optimized learning rate and evaluate it on your test data.\n",
    "1. Recognizing that the batch size is also important for training speed, you decide to extend your above analysis to also find the optimal batch size. Once again, train a model with you optimized learning rate *and* batch size and evaluate it on your test data.\n",
    "1. You have heard that momentum is important. You know that many optimizers already incorporate momentum by default, but you are now forced by your evil teacher to use SGD and otherwise repeat (1) and (2). You decide to extend your above analysis to also find the optimal momentum for SGD (see https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/SGD for how to set it). Once again, train a model with you optimized learning rate, batch size, *and* momentum and evaluate it on your test data.\n",
    "\n",
    "**See slides for more details!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1\n",
    "\n",
    "Consider last exercise (i.e. the MNIST data). Suppose you are restricted to **training for only 2 epochs** but still want a good model. You recognize that finding the right learning rate is going to be very important. For this reason, you split your training data into a train and a validation set and use the validation set to find the optimal learning rate. Train a model with you optimized learning rate and evaluate it on your test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54000, 28, 28) (54000,) (6000, 28, 28) (6000,) (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# A simply way to scale data. Remember pixels are in [0, 255] so this ensures [0, 1]\n",
    "x_train = x_train / 255\n",
    "x_test = x_test / 255\n",
    "\n",
    "# Split train data to also get val data\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train,test_size=0.1,random_state=43)\n",
    "\n",
    "print(x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is (parts of) a model to get you started.\n",
    "\n",
    "It is very helpful to wrap it inside a function since you want to call it multiple times in a loop.\n",
    "\n",
    "Take note of the \"Flatten\" layer. This is important to reshape your data from (28, 28) to (784,).\n",
    "\n",
    "Alternatively, you could reshape your data (the x's). This can be done using:\n",
    "\n",
    "$\\texttt{x = x.reshape(n, 784)}$ \n",
    "\n",
    "where $n$ is the number of samples (60k for training, 10k for test).\n",
    "\n",
    "Then you don't need the Flatten layer, but remember to still specify an input shape of your first layer (i.e. 784 if you have done this reshaping).\n",
    "\n",
    "**Note**: Do feel free to experiment with the number of layers, nodes per layer, and optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(learning_rate):\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "        tf.keras.layers.Dense(32, activation='relu'),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(10, activation='softmax'),\n",
    "    ])\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "    model.compile(\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        optimizer=optimizer,\n",
    "        metrics=['accuracy'],\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us look at single run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 2.3048 - accuracy: 0.0697 - val_loss: 2.2799 - val_accuracy: 0.0792\n",
      "Epoch 2/2\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 2.2605 - accuracy: 0.0932 - val_loss: 2.2405 - val_accuracy: 0.1097\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 2.2406 - accuracy: 0.1114\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.240609884262085, 0.11140000075101852]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_model(0.0001) # insert desired learning rate\n",
    "model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=2)\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.3507 - accuracy: 0.8948 - val_loss: 0.2073 - val_accuracy: 0.9370\n",
      "Epoch 2/2\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.1745 - accuracy: 0.9481 - val_loss: 0.1671 - val_accuracy: 0.9480\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1662 - accuracy: 0.9496\n",
      "Epoch 1/2\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.8099 - accuracy: 0.7815 - val_loss: 0.3959 - val_accuracy: 0.8857\n",
      "Epoch 2/2\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.3373 - accuracy: 0.9027 - val_loss: 0.3179 - val_accuracy: 0.9035\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.2881 - accuracy: 0.9159\n",
      "Epoch 1/2\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 2.1212 - accuracy: 0.2800 - val_loss: 1.8605 - val_accuracy: 0.5053\n",
      "Epoch 2/2\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 1.4945 - accuracy: 0.6520 - val_loss: 1.1510 - val_accuracy: 0.7547\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 1.1300 - accuracy: 0.7549\n",
      "Epoch 1/2\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 2.3267 - accuracy: 0.1138 - val_loss: 2.3218 - val_accuracy: 0.1175\n",
      "Epoch 2/2\n",
      "1688/1688 [==============================] - 3s 1ms/step - loss: 2.3214 - accuracy: 0.1156 - val_loss: 2.3166 - val_accuracy: 0.1202\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 2.3228 - accuracy: 0.1108\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Learning rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9496</td>\n",
       "      <td>0.10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.9159</td>\n",
       "      <td>0.01000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.7549</td>\n",
       "      <td>0.00100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.1108</td>\n",
       "      <td>0.00001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  Learning rate\n",
       "0    0.9496        0.10000\n",
       "1    0.9159        0.01000\n",
       "2    0.7549        0.00100\n",
       "3    0.1108        0.00001"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rates = [0.1,0.01,0.001,0.00001] # must be positive floats. Default depends on optimizer\n",
    "\n",
    "results = []\n",
    "\n",
    "for learning_rate in learning_rates:\n",
    "    model = build_model(learning_rate)\n",
    "    model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=2) # you may want to use verbose=0 here to not get spammed. Also remember to use epochs=2\n",
    "    loss, acc = model.evaluate(x_test, y_test)\n",
    "    results.append((acc, learning_rate))\n",
    "    \n",
    "results = pd.DataFrame(results, columns=['Accuracy', 'Learning rate'])\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Learning rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9496</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  Learning rate\n",
       "0    0.9496            0.1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[results['Accuracy'] == results['Accuracy'].max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate final model.\n",
    "# Remember to use both train and val data for training for best performance! \n",
    "# Similar to what we have done in all the other exercises/assignments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2\n",
    "\n",
    "Recognizing that the batch size is also important for training speed, you decide to extend your above analysis to also find the optimal batch size. Once again, train a model with you optimized learning rate *and* batch size and evaluate it on your test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.3314 - accuracy: 0.9008 - val_loss: 0.2153 - val_accuracy: 0.9350\n",
      "Epoch 2/2\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.1658 - accuracy: 0.9494 - val_loss: 0.1725 - val_accuracy: 0.9468\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1603 - accuracy: 0.9505\n",
      "Epoch 1/2\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.3404 - accuracy: 0.8966 - val_loss: 0.3211 - val_accuracy: 0.9052\n",
      "Epoch 2/2\n",
      "1688/1688 [==============================] - 3s 1ms/step - loss: 0.1654 - accuracy: 0.9510 - val_loss: 0.1460 - val_accuracy: 0.9517\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1511 - accuracy: 0.9531\n",
      "Epoch 1/2\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.3421 - accuracy: 0.8969 - val_loss: 0.2581 - val_accuracy: 0.9200\n",
      "Epoch 2/2\n",
      "1688/1688 [==============================] - 2s 1ms/step - loss: 0.1708 - accuracy: 0.9486 - val_loss: 0.3104 - val_accuracy: 0.9110\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.2808 - accuracy: 0.9123\n",
      "Epoch 1/2\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.3495 - accuracy: 0.8953 - val_loss: 0.2429 - val_accuracy: 0.9215\n",
      "Epoch 2/2\n",
      "1688/1688 [==============================] - 3s 1ms/step - loss: 0.1708 - accuracy: 0.9491 - val_loss: 0.1857 - val_accuracy: 0.9433\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1671 - accuracy: 0.9494\n",
      "Epoch 1/2\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.3458 - accuracy: 0.8954 - val_loss: 0.2200 - val_accuracy: 0.9310\n",
      "Epoch 2/2\n",
      "1688/1688 [==============================] - 2s 1ms/step - loss: 0.1673 - accuracy: 0.9495 - val_loss: 0.1630 - val_accuracy: 0.9507\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1492 - accuracy: 0.9568\n",
      "Epoch 1/2\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.8337 - accuracy: 0.7653 - val_loss: 0.3969 - val_accuracy: 0.8797\n",
      "Epoch 2/2\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.3256 - accuracy: 0.9055 - val_loss: 0.3010 - val_accuracy: 0.9102\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.2770 - accuracy: 0.9190\n",
      "Epoch 1/2\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.7735 - accuracy: 0.7861 - val_loss: 0.3994 - val_accuracy: 0.8790\n",
      "Epoch 2/2\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.3285 - accuracy: 0.9058 - val_loss: 0.3044 - val_accuracy: 0.9093\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.2826 - accuracy: 0.9182\n",
      "Epoch 1/2\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.8020 - accuracy: 0.7802 - val_loss: 0.3939 - val_accuracy: 0.8885\n",
      "Epoch 2/2\n",
      "1688/1688 [==============================] - 3s 1ms/step - loss: 0.3385 - accuracy: 0.9032 - val_loss: 0.3187 - val_accuracy: 0.9062\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.2940 - accuracy: 0.9147\n",
      "Epoch 1/2\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.7839 - accuracy: 0.7845 - val_loss: 0.3927 - val_accuracy: 0.8842\n",
      "Epoch 2/2\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.3384 - accuracy: 0.9021 - val_loss: 0.3174 - val_accuracy: 0.9083\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.2922 - accuracy: 0.9132\n",
      "Epoch 1/2\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.7648 - accuracy: 0.7839 - val_loss: 0.4036 - val_accuracy: 0.8833\n",
      "Epoch 2/2\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.3368 - accuracy: 0.9040 - val_loss: 0.3169 - val_accuracy: 0.9058\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.2913 - accuracy: 0.9179\n",
      "Epoch 1/2\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 2.1061 - accuracy: 0.3351 - val_loss: 1.8544 - val_accuracy: 0.5002\n",
      "Epoch 2/2\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 1.4838 - accuracy: 0.6554 - val_loss: 1.1490 - val_accuracy: 0.7525\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 1.1115 - accuracy: 0.7630\n",
      "Epoch 1/2\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 2.0977 - accuracy: 0.3081 - val_loss: 1.8274 - val_accuracy: 0.5205\n",
      "Epoch 2/2\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 1.4624 - accuracy: 0.6535 - val_loss: 1.1231 - val_accuracy: 0.7493\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 1.1024 - accuracy: 0.7613\n",
      "Epoch 1/2\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 2.1033 - accuracy: 0.3253 - val_loss: 1.8110 - val_accuracy: 0.5578\n",
      "Epoch 2/2\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 1.4510 - accuracy: 0.6452 - val_loss: 1.1461 - val_accuracy: 0.7150\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 1.1204 - accuracy: 0.7285\n",
      "Epoch 1/2\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 2.0486 - accuracy: 0.3910 - val_loss: 1.7505 - val_accuracy: 0.5725\n",
      "Epoch 2/2\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 1.3887 - accuracy: 0.6914 - val_loss: 1.0812 - val_accuracy: 0.7753\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 1.0460 - accuracy: 0.7853\n",
      "Epoch 1/2\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 2.1075 - accuracy: 0.3343 - val_loss: 1.8249 - val_accuracy: 0.5295\n",
      "Epoch 2/2\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 1.4577 - accuracy: 0.6673 - val_loss: 1.1288 - val_accuracy: 0.7320\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 1.1088 - accuracy: 0.7453\n",
      "Epoch 1/2\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 2.3326 - accuracy: 0.1168 - val_loss: 2.3336 - val_accuracy: 0.1155\n",
      "Epoch 2/2\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 2.3256 - accuracy: 0.1210 - val_loss: 2.3267 - val_accuracy: 0.1197\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 2.3281 - accuracy: 0.1199\n",
      "Epoch 1/2\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 2.3276 - accuracy: 0.1336 - val_loss: 2.3240 - val_accuracy: 0.1362\n",
      "Epoch 2/2\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 2.3212 - accuracy: 0.1378 - val_loss: 2.3177 - val_accuracy: 0.1397\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 2.3164 - accuracy: 0.1397\n",
      "Epoch 1/2\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 2.3340 - accuracy: 0.0778 - val_loss: 2.3298 - val_accuracy: 0.0820\n",
      "Epoch 2/2\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 2.3256 - accuracy: 0.0881 - val_loss: 2.3217 - val_accuracy: 0.0900\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 2.3263 - accuracy: 0.0895\n",
      "Epoch 1/2\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 2.3216 - accuracy: 0.1474 - val_loss: 2.3256 - val_accuracy: 0.1453\n",
      "Epoch 2/2\n",
      "1688/1688 [==============================] - 2s 1ms/step - loss: 2.3161 - accuracy: 0.1496 - val_loss: 2.3202 - val_accuracy: 0.1472\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 2.3181 - accuracy: 0.1511\n",
      "Epoch 1/2\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 2.3373 - accuracy: 0.0712 - val_loss: 2.3360 - val_accuracy: 0.0742\n",
      "Epoch 2/2\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 2.3325 - accuracy: 0.0722 - val_loss: 2.3312 - val_accuracy: 0.0753\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 2.3306 - accuracy: 0.0714\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Learning rate</th>\n",
       "      <th>Batch size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9505</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.9531</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.9123</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.9494</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.9568</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.9190</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.9182</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.9147</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.9132</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.9179</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.7630</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.7613</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.7285</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.7853</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.7453</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.1199</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.1397</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.1511</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0714</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Accuracy  Learning rate  Batch size\n",
       "0     0.9505        0.10000           8\n",
       "1     0.9531        0.10000          16\n",
       "2     0.9123        0.10000          32\n",
       "3     0.9494        0.10000          64\n",
       "4     0.9568        0.10000         128\n",
       "5     0.9190        0.01000           8\n",
       "6     0.9182        0.01000          16\n",
       "7     0.9147        0.01000          32\n",
       "8     0.9132        0.01000          64\n",
       "9     0.9179        0.01000         128\n",
       "10    0.7630        0.00100           8\n",
       "11    0.7613        0.00100          16\n",
       "12    0.7285        0.00100          32\n",
       "13    0.7853        0.00100          64\n",
       "14    0.7453        0.00100         128\n",
       "15    0.1199        0.00001           8\n",
       "16    0.1397        0.00001          16\n",
       "17    0.0895        0.00001          32\n",
       "18    0.1511        0.00001          64\n",
       "19    0.0714        0.00001         128"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rates = [0.1,0.01,0.001,0.00001] # must be positive floats. Default depends on optimizer\n",
    "batch_sizes = [8,16,32,64,128] # # must be positive ints. Default is 32\n",
    "\n",
    "results = []\n",
    "\n",
    "for learning_rate in learning_rates:\n",
    "    for batch_size in batch_sizes:\n",
    "        model = build_model(learning_rate)\n",
    "        model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=2)# remember to pass in batch_size here! Also remember to use epochs=2\n",
    "        loss, acc = model.evaluate(x_test, y_test)\n",
    "        results.append((acc, learning_rate, batch_size))\n",
    "    \n",
    "results = pd.DataFrame(results, columns=['Accuracy', 'Learning rate', 'Batch size'])\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Learning rate</th>\n",
       "      <th>Batch size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.9568</td>\n",
       "      <td>0.1</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  Learning rate  Batch size\n",
       "4    0.9568            0.1         128"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[results['Accuracy'] == results['Accuracy'].max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate final model.\n",
    "# Remember to use both train and val data for training for best performance! \n",
    "# Similar to what we have done in all the other exercises/assignments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exericse 3\n",
    "\n",
    "You have heard that momentum is important. You know that many optimizers already incorporate momentum by default, but you are now forced by your evil teacher to use SGD and otherwise repeat (1) and (2). You decide to extend your above analysis to also find the optimal momentum for SGD (see https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/SGD for how to set it). Once again, train a model with you optimized learning rate, batch size, *and* momentum and evaluate it on your test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_with_momentum(learning_rate, momentum):\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "        tf.keras.layers.Dense(32, activation='relu'),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(10, activation='softmax'),\n",
    "    ])\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=momentum)\n",
    "    model.compile(\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        optimizer=optimizer,\n",
    "        metrics=['accuracy'],\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1386 - accuracy: 0.9564\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1912 - accuracy: 0.9371\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1305 - accuracy: 0.9590\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1777 - accuracy: 0.9465\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.2602 - accuracy: 0.9360\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1528 - accuracy: 0.9540\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1371 - accuracy: 0.9582\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1306 - accuracy: 0.9604\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1561 - accuracy: 0.9540\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3621 - accuracy: 0.8998\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1399 - accuracy: 0.9555\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1410 - accuracy: 0.9583\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1309 - accuracy: 0.9614\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1412 - accuracy: 0.9582\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3159 - accuracy: 0.9222\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1430 - accuracy: 0.9568\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1731 - accuracy: 0.9444\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1499 - accuracy: 0.9540\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1636 - accuracy: 0.9494\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3324 - accuracy: 0.9260\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1491 - accuracy: 0.9514\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1345 - accuracy: 0.9564\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1469 - accuracy: 0.9539\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1439 - accuracy: 0.9556\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3067 - accuracy: 0.9244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [02:35<07:45, 155.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 0.2914 - accuracy: 0.9163\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.2742 - accuracy: 0.9190\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.2221 - accuracy: 0.9357\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1786 - accuracy: 0.9474\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1408 - accuracy: 0.9560\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.2784 - accuracy: 0.9210\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.2858 - accuracy: 0.9174\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.2566 - accuracy: 0.9245\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1895 - accuracy: 0.9410\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1378 - accuracy: 0.9559\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2790 - accuracy: 0.9164\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2907 - accuracy: 0.9133\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.2462 - accuracy: 0.9308\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1916 - accuracy: 0.9422\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1460 - accuracy: 0.9568\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.2858 - accuracy: 0.9160\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2735 - accuracy: 0.9222\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.2442 - accuracy: 0.9290\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1887 - accuracy: 0.9431\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1293 - accuracy: 0.9614\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.2895 - accuracy: 0.9153\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2831 - accuracy: 0.9171\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.2329 - accuracy: 0.9288\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1923 - accuracy: 0.9445\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1512 - accuracy: 0.9526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [05:23<05:25, 162.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 1.0878 - accuracy: 0.7463\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.8041 - accuracy: 0.8097\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.5593 - accuracy: 0.8591\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3914 - accuracy: 0.8909\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.2876 - accuracy: 0.9168\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 1.0258 - accuracy: 0.7743\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.9886 - accuracy: 0.7660\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.5666 - accuracy: 0.8554\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.4033 - accuracy: 0.8849\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2924 - accuracy: 0.9165\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.9256 - accuracy: 0.7956\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.9092 - accuracy: 0.7897\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.5549 - accuracy: 0.8616\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3990 - accuracy: 0.8887\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.2898 - accuracy: 0.9174\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 1.0691 - accuracy: 0.7596\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.8490 - accuracy: 0.8044\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.5510 - accuracy: 0.8579\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.4024 - accuracy: 0.8854\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2919 - accuracy: 0.9157\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 1.0373 - accuracy: 0.7662\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.7982 - accuracy: 0.8001\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.5893 - accuracy: 0.8500\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3995 - accuracy: 0.8937\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2822 - accuracy: 0.9166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [08:24<02:51, 171.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 2.3207 - accuracy: 0.1071\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 2.2960 - accuracy: 0.1134\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 2.3079 - accuracy: 0.1172\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 2.2802 - accuracy: 0.1389\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 2.2619 - accuracy: 0.2259\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 2.2996 - accuracy: 0.0750\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 2.3078 - accuracy: 0.1106\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 2.2984 - accuracy: 0.1392\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 2.2784 - accuracy: 0.1240\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 2.2559 - accuracy: 0.2211\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 2.3410 - accuracy: 0.1058\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 2.3479 - accuracy: 0.0859\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 2.2974 - accuracy: 0.0900\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 2.3233 - accuracy: 0.0751\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 2.2526 - accuracy: 0.1266\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 2.2796 - accuracy: 0.1282\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 2.3567 - accuracy: 0.0787\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 2.2830 - accuracy: 0.1557\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 2.2730 - accuracy: 0.1425\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 2.1869 - accuracy: 0.2628\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 2.3380 - accuracy: 0.0988\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 2.2779 - accuracy: 0.1227\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 2.2802 - accuracy: 0.1020\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 2.2954 - accuracy: 0.1174\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 2.2161 - accuracy: 0.1805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [12:26<00:00, 186.72s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Learning rate</th>\n",
       "      <th>Batch size</th>\n",
       "      <th>Momentum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9564</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>8</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.9371</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>8</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.9590</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>8</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.9465</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>8</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.9360</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>8</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.0988</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>128</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.1227</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>128</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.1020</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>128</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.1174</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>128</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.1805</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>128</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Accuracy  Learning rate  Batch size  Momentum\n",
       "0     0.9564        0.10000           8      0.10\n",
       "1     0.9371        0.10000           8      0.25\n",
       "2     0.9590        0.10000           8      0.50\n",
       "3     0.9465        0.10000           8      0.75\n",
       "4     0.9360        0.10000           8      0.90\n",
       "..       ...            ...         ...       ...\n",
       "95    0.0988        0.00001         128      0.10\n",
       "96    0.1227        0.00001         128      0.25\n",
       "97    0.1020        0.00001         128      0.50\n",
       "98    0.1174        0.00001         128      0.75\n",
       "99    0.1805        0.00001         128      0.90\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "learning_rates = [0.1,0.01,0.001,0.00001] # must be positive floats. Default depends on optimizer\n",
    "batch_sizes = [8,16,32,64,128] # # must be positive ints. Default is 32\n",
    "momentums = [0.1,0.25,0.5,0.75,0.9] # must be in [0, 1). Default (for SGD) is 0.0\n",
    "\n",
    "results = []\n",
    "\n",
    "for learning_rate in tqdm(learning_rates):\n",
    "    for batch_size in batch_sizes:\n",
    "        for momentum in momentums:\n",
    "            model = build_model_with_momentum(learning_rate, momentum=momentum)            \n",
    "            model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=2,verbose=0)# remember to pass in batch_size here! Also remember to use epochs=2\n",
    "            loss, acc = model.evaluate(x_test, y_test)\n",
    "            results.append((acc, learning_rate, batch_size, momentum))\n",
    "    \n",
    "results = pd.DataFrame(results, columns=['Accuracy', 'Learning rate', 'Batch size', 'Momentum'])\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Learning rate</th>\n",
       "      <th>Batch size</th>\n",
       "      <th>Momentum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.9614</td>\n",
       "      <td>0.10</td>\n",
       "      <td>32</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.9614</td>\n",
       "      <td>0.01</td>\n",
       "      <td>64</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Accuracy  Learning rate  Batch size  Momentum\n",
       "12    0.9614           0.10          32       0.5\n",
       "44    0.9614           0.01          64       0.9"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[results['Accuracy'] == results['Accuracy'].max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate final model.\n",
    "# Remember to use both train and val data for training for best performance! \n",
    "# Similar to what we have done in all the other exercises/assignments"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('amlfall22')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "d3cedec8935a2c28d6fd602c3007747750e2af1c4c937c29fac0d323bf1b544b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
