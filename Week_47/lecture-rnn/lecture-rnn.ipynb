{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## DS807: Applied machine learning\n",
    "Christian M. Dahl. cmd@sam.sdu.dk.\n",
    "\n",
    "### Recurrent neural networks\n",
    "\n",
    "Notes: For the purpose of this notebook, DLWP refers to Deep Learning with Python by Francois Collet (ISBN10: 9781617294433).\n",
    "\n",
    "### Version\n",
    "\n",
    "v2: 25-11-2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Introduction\n",
    "\n",
    "*Recurrent neural networks* (RNNs) are a type of neural network used to handle/analyze *sequential* data, i.e. data where the next data point is somehow related to the prior data points.\n",
    "\n",
    "This is the case in many applications, including forecasting sales, analyzing text, working with videos, and interacting with dynamic environments.\n",
    "\n",
    "RNNs are a *special case* of feed forward neural networks - just as convolutional neural networks (CNNs) are. And just as CNNs allowed us to more easily work with grids of values (such as images), RNNs more easily allow us to work with sequences of values (such as time series or text).\n",
    "\n",
    "In this lecture, we will learn how to use RNNs to solve tasks of modelling sequences. Today, we will learn the fundamentals of RNNs, including showcasing how they can be used to solve regression and classification problems.\n",
    "\n",
    "Next week, we will use an RNN to generate text. In particular, we will use the works of Shakespeare in order to train a neural network that can act as a playwriter - in the style of Shakespeare! In order to write meaningful text, we must know what is already written! Hence, we exploit the recurrent/sequential structure of the data in order to create meaningful text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Program\n",
    "\n",
    "After this lecture, you will:\n",
    "1. Know when to use RNNs, including considerations for the types of data to use.\n",
    "1. Know about different types of RNNs (standard, LSTM, GRU, and bidirectional).\n",
    "1. Know how to handle text data, including n-grams and embeddings.\n",
    "1. Know how to build and train RNNs, including considerations for optimization and regularization.\n",
    "1. Have applied your knowledge in order to solve classification problems.\n",
    "1. Have applied your knowledge in order to use an RNN as a playwriter in the style of Shakespeare (i.e. text generation).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"./graphics/examplesofsequences.png\" alt=\"Drawing\" style=\"width: 1000px;\"/>\n",
    "\n",
    "Source: \"Andrew Ng\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is an RNN?\n",
    "\n",
    "An RNN is a type of network that for each input outputs both the standard output we are familiar with, as well as a \"state\" that is passed on as part of the input for the next period.\n",
    "\n",
    "This way, the network makes a prediction - as we are used to - and *summarizes the information needed to be passed on*. In this way, the next prediction the network makes (can) use this information as part of its input.\n",
    "\n",
    "As such, an RNN is a type of network with a \"loop\", in that it feeds into itself. This loop is sometimes called the \"recurrent connection\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Input, output, and the recurrent connection\n",
    "\n",
    "<img src=\"./graphics/figure_6-9.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n",
    "Source: \"DLWP\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Neural networks are directed acyclic graphs\n",
    "\n",
    "We train neural networks by backpropagation, *which is not possible if a true loop exists*.\n",
    "\n",
    "Such models, with no true loops, are known as directed acyclic graphs (DAGs). Any neural network can be described as a DAG.\n",
    "\n",
    "But then, how does RNNs work? We use something called \"unfolding\", which is to say that we \"unfold\" the loop so that it takes the form of a DAG.\n",
    "\n",
    "This is possible since we never in practice loop an infinite number of times, but rather some finite number, *k*.\n",
    "\n",
    "As such, a *k*-loop may be unfolded into a DAG consisting of *k* parts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Recurrent cells and unfolding\n",
    "\n",
    "Usually, a recurrent neural network looks something like the image below - i.e. it has a \"loop\" where it feeds into itself (left). This can then be \"unfolded\" (right), in which way it looks more like a regular network, with an additional input and output (these are the \"hidden states\").\n",
    "\n",
    "<img src=\"./graphics/RNN_illustrating_same_weights_01.png\" alt=\"Drawing\" style=\"width: 1500px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Recurrent cells - what is the hidden state?\n",
    "\n",
    "A key part of recurrent neural networks is the hidden state, specifically how we construct (output) it and how we use (input) it. \n",
    "\n",
    "The idea of the hidden state is to pass along historical information that will be used at later stages.\n",
    "\n",
    "This can be done in many ways. You can use the raw output, construct some \"optimal\" summary of the history, or even use earlier raw inputs!\n",
    "\n",
    "In general, finding some \"optimal\" summary is the best method. This \"optimal\" summary is typically found exactly how we normally train neural networks, i.e. as part of the training through stochastic gradient descent.\n",
    "\n",
    "However, there any multiples types of recurrent cells, and these differ in how they construct, use, and pass on their hidden states."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example:\n",
    "\n",
    "**Text:** \"Yesterday, Harry Potter met Hermione Granger\"\n",
    "\n",
    "**Task:** Identify if word in text is a name\n",
    "\n",
    "**Define vocabulary:**\n",
    "\n",
    "$ V = (a,aaron,...,granger,...,harry,...,hermione,...,\n",
    "    met,...,potter,...,yesterday,...,zulu) $\n",
    "\n",
    "\n",
    "**Define output:**\n",
    "\n",
    "$(o_1,o_2,o_3,o_4,o_5,o_6)= (0,1,1,0,1,1)$\n",
    "\n",
    "**Define input (one-hot-encoding):**\n",
    "\n",
    "$ x_1 = (0,0,...,0,...,0,...,0,...,0,...,0,...,1,...,0) $,\n",
    "$ x_2 = (0,0,...,0,...,1,...,0,...,0,...,0,...,0,...,0) $,\n",
    "$ x_3 = (0,0,...,0,...,0,...,0,...,0,...,1,...,0,...,0) $,\n",
    "$ x_4 = (0,0,...,0,...,0,...,0,...,1,...,0,...,0,...,0) $,\n",
    "$ x_5 = (0,0,...,0,...,0,...,1,...,0,...,0,...,0,...,0) $,\n",
    "$ x_6 = (0,0,...,1,...,0,...,0,...,0,...,0,...,0,...,0) $.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "$h_1 = g_1(W_{hh}*h_0 + W_{hx}*x_1 + b_h) \\\\ \n",
    "o_1 = g_2(W_{oh}*h_1 + b_o) \\\\ \n",
    "h_2 = g_1(W_{hh}*h_1 + W_{hx}*x_2 + b_h) \\\\\n",
    "o_2 = g_2(W_{oh}*h_2 + b_o) \\\\\n",
    "... \\\\\n",
    "... \\\\\n",
    "h_t = g_1(W_{hh}*h_{t-1} + W_{hx}*x_t + b_h) \\\\\n",
    "o_t = g_2(W_{oh}*h_{t} + b_o) \\\\\n",
    "g_1: \\text{tanh or ReLu} \\\\ \n",
    "g_2: \\text{sigmoid or softmax}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Types of recurrent cells\n",
    "\n",
    "There are three main types of recurrent cells that are used: the $\\texttt{SimpleRNN}$, $\\texttt{LSTM}$, and $\\texttt{GRU}$ layers.\n",
    "\n",
    "In practice, the first approach is very naïve and often not good, but it serves as a starting point for understanding the more complex versions. Its main weakness is that it has difficulties learning long-term dependencies, as it is not able to effectively pass along information over long distances (i.e. where it needs to be carried forward many steps).\n",
    "\n",
    "Both LSTM (long short-term memory) and GRU (gated recurrent unit) layers are widely used and very powerful. They both aim to solve the issues related to carrying information forward many steps.\n",
    "\n",
    "Further, in some cases it makes sense to pass information along *backwards*. This may seem counterintuitive, and in time-series forecasting it certainly often does not make sense, but think of understanding a movie review. The start of the review may well be as important as the end of the review, for which reason reading it \"backwards\" can still provide information about its contents.\n",
    "\n",
    "An extension of this idea is to *use both ways*. That is, have a part of your NN that reads the sequence \"forward\" and another that reads it \"backwards\". Such a combination is known as a *bidirectional* layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Simple RNN\n",
    "\n",
    "The most *simple* - hence the name - way to build a recurrent layer is to simply **use its output as the state it passes along to the next step**.\n",
    "\n",
    "This what the $\\texttt{SimpleRNN}$ layer does. \n",
    "\n",
    "However, it is problematic for the same reasons that training deep models (without residual connections) is problematic - backpropagating back through the steps now leads to gradients that easily collapse to zero or diverge, making learning difficult.\n",
    "\n",
    "Further, the information will have difficulties traversing long distances (as it will be non-linearly transformed at each step).\n",
    "\n",
    "A $\\texttt{SimpleRNN}$ layer with *i* input features and *j* nodes will have $(j + i + 1)j$ trainable parameters (assuming for simplicity that there is no output layer, i.e., $o_t=h_t$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Simple RNN\n",
    "\n",
    "<img src=\"./graphics/SimpleRNN.jpg\" alt=\"Drawing\" style=\"width: 800px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Building a $\\texttt{SimpleRNN}$ layer\n",
    "\n",
    "**Note**: The default activation of this layer is the hyperbolic tangent (and not linear, as with many layers). If you set return_sequences=False, the shape of this output is (batch_size, nb_nodes/units). If you set return_sequences=True, the shape of this output is (batch_size, nb_timesteps, nb_nodes/units)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf-version 2.10.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(f'tf-version {tf.__version__}')\n",
    "nb_input_features = 10000\n",
    "nb_timesteps = 6\n",
    "nb_nodes = 6\n",
    "\n",
    "simple_rnn_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.SimpleRNN(nb_nodes, \n",
    "                              input_shape=(nb_timesteps, nb_input_features),\n",
    "                              return_sequences=True),\n",
    "    tf.keras.layers.SimpleRNN(units=nb_timesteps, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_2 (SimpleRNN)    (None, 6, 6)              60042     \n",
      "                                                                 \n",
      " simple_rnn_3 (SimpleRNN)    (None, 6)                 78        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 60,120\n",
      "Trainable params: 60,120\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Number of trainable parameters (o=h) = 60042\n",
      "Number of trainable parameters (o=g2(h)) = 60042 +78\n"
     ]
    }
   ],
   "source": [
    "simple_rnn_model.summary()\n",
    "\n",
    "print(\n",
    "    f'Number of trainable parameters (o=h) = '\n",
    "    f'{(nb_input_features + nb_nodes + 1) * nb_nodes}'\n",
    ")\n",
    "print(\n",
    "    f'Number of trainable parameters (o=g2(h)) = '\n",
    "    f'{(nb_input_features + nb_nodes + 1) * nb_nodes} +'\n",
    "    f'{(nb_nodes + nb_timesteps + 1) * nb_timesteps}'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Long Short Term Memory (LSTM)\n",
    "\n",
    "LSTM layers were introduced in \"Hochreiter, S., & Schmidhuber, J. (1997). Long short-term memory. Neural computation, 9(8), 1735-1780\".\n",
    "\n",
    "They address the problem of retaining information over long sequences while making backpropagation feasible even for very long sequences.\n",
    "\n",
    "How? They add an additional state that is passed along, typically called the *carry* track. Crucially, the carry track is not affected directly by any other operation than multiplication and addition, making information easier to retain over long periods while also allowing for gradients to easier flow through long sequences.\n",
    "\n",
    "**Note**: The exact structure of an LSTM cell is often interpreted as containing \"forget\" gates. Chollet warns about this interpretation. We do not strictly enforce \"forget\" gates, and interpreting what they do is far more complex."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example where long range dependence is needed \n",
    "<img src=\"./graphics/ingvald_bleken_all.png\" alt=\"Drawing\" style=\"width: 1000px;\"/>\n",
    "\n",
    "**Note**:  Spouse is located deep in the text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The LSTM cell and the carry track\n",
    "\n",
    "<img src=\"./graphics/The-structure-of-the-Long-Short-Term-Memory-LSTM-neural-network-Reproduced-from-Yan_W640.jpg\" alt=\"Drawing\" style=\"width: 600px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## LSTM Cells\n",
    "\n",
    "LSTM cells are a type of recurrent neural network architecture designed for long-term information retention. \n",
    "\n",
    "### Key Components\n",
    "\n",
    "#### 1. Cell State\n",
    "- Acts as a conveyor belt through the LSTM.\n",
    "- Transports and stores information across the sequence.\n",
    "\n",
    "#### 2. Hidden State\n",
    "- Transfers information down the sequence.\n",
    "- Interacts with the cell through various gates.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Core Gates\n",
    "\n",
    "#### a. Forget Gate\n",
    "- Decides what information to discard from the cell state.\n",
    "- Uses a sigmoid function to output values between 0 (forget) and 1 (keep).\n",
    "\n",
    "#### b. Input Gate\n",
    "- Updates the cell state with new information.\n",
    "- Consists of two parts:\n",
    "  - A sigmoid layer deciding which values to update.\n",
    "  - A tanh layer creating a vector of new candidate values.\n",
    "\n",
    "#### c. Output Gate\n",
    "- Determines the next hidden state.\n",
    "- Uses the current input and previous hidden state to decide the output.\n",
    "<br></br>\n",
    "\n",
    "### Operations\n",
    "- The cell state is modified through a series of steps involving these gates.\n",
    "- The forget gate discards irrelevant information.\n",
    "- The input gate adds new information.\n",
    "- The output gate updates the hidden state based on the cell state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Long Short Term Memory (LSTM)\n",
    "    \n",
    "<img src=\"./graphics/a-A-vanilla-LSTM-cell-b-Equations-of-a-vanilla-LSTM-cell.ppm.png\" alt=\"Drawing\" style=\"width: 1000px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exercise\n",
    "\n",
    "Based on the two previous slides identify (within the LSTM cell)\n",
    "- input gate\n",
    "- forget gate\n",
    "- output gate\n",
    "- memory cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Key take-away from LSTM layers\n",
    "\n",
    "In using LSTM layers, and in understanding why they often perform so much better than the naïve recurrent layer, knowing the importance of the carry track is crucial.\n",
    "\n",
    "Often when solving tasks where recurrent layers are useful, the dependencies are long. Think of text data. To analyze it successfully, we *need* to be able to use information about words distanced far from each other.\n",
    "\n",
    "The introduction of the additional components of the LSTM layer (as opposed to the naïve approach) does, however, lead to many more parameters (specifically four times as many).\n",
    "\n",
    "1. Input is now transformed four different ways.\n",
    "1. Same with the hidden state(s) (i.e. the \"normal\" portion and the carry track together).\n",
    "\n",
    "The activations used in an LSTM cell tend to be a combination of the hyperbolic tangent and the sigmoid (where the sigmoid parts are sometimes referred to as forget gates).\n",
    "\n",
    "An $\\texttt{LSTM}$ layer with *i* input features and *j* nodes will have $4(j + i + 1)j$ trainable parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Key take-away from LSTM layers\n",
    "\n",
    "### Sigmoid vs Tanh\n",
    "\n",
    "<img src=\"./graphics/tanh.jpg\" alt=\"Drawing\" style=\"width: 1000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Building an $\\texttt{LSTM}$ layer\n",
    "\n",
    "**Note**: The default activation of this layer is the hyperbolic tangent (and not linear, as with many layers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 4)                 240       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 240\n",
      "Trainable params: 240\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Number of trainable parameters = 240\n"
     ]
    }
   ],
   "source": [
    "nb_input_features = 10\n",
    "nb_timesteps = 5\n",
    "nb_nodes = 4\n",
    "\n",
    "lstm_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.LSTM(nb_nodes, \n",
    "                         input_shape=(nb_timesteps, nb_input_features))\n",
    "])\n",
    "\n",
    "lstm_model.summary()\n",
    "\n",
    "print(f'Number of trainable parameters = \n",
    "      {4 * (nb_input_features + nb_nodes + 1) * nb_nodes}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Gated Recurrent Unit (GRU)\n",
    "\n",
    "GRU layers were introduced in \"Cho, K., Van Merriënboer, B., Gulcehre, C., Bahdanau, D., Bougares, F., Schwenk, H., & Bengio, Y. (2014). Learning phrase representations using RNN encoder-decoder for statistical machine translation. arXiv preprint arXiv:1406.1078\".\n",
    "\n",
    "They are a somewhat simpler version of an LSTM layer (the capability of an LSTM layer weakly dominates that of a corresponding GRU layer). However, in practice it does in some cases outperform LSTM layers (with fewer parameters).\n",
    "\n",
    "Works by combining the \"forget\" and input gates, and merging the \"carry track\" with the hidden state. This means the number of parameters is now \"only\" three times larger than that of the naïve approach.\n",
    "\n",
    "A $\\texttt{GRU}$ layer with *i* input features and *j* nodes will have $3(j + i + 1)j$ trainable parameters OR $3(j + i + 2)j$ trainable parameters, depending on the exact implementation; these are the implementations in TensorFlow 1.x and 2.x, respectively.\n",
    "\n",
    "The additional $3j$ parameters in the second case is due to separate bias terms for input and recurrent kernels. This is a hyperparameter you can choose whether you want to use. It is used by default in TensorFlow 2.x: https://newbedev.com/calculating-the-number-of-parameters-of-a-gru-layer-keras#:~:text=As%20you%20can%20see%2C%20the%20default%20parameter%20of,%2A%203%20%2A%202%20%3D%209600%20in%20tensorflow2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Gated Recurrent Unit (GRU)\n",
    "\n",
    "<img src=\"./graphics/1920px-Gated_Recurrent_Unit,_base_type.svg.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n",
    "<img src=\"./graphics/GRUmath.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gated Recurrent Unit (GRU)\n",
    "\n",
    "GRU is a type of recurrent neural network architecture optimized for sequence modeling and handling long-term dependencies.\n",
    "\n",
    "## Key Features\n",
    "\n",
    "### Simplified Structure\n",
    "- GRU units are designed to be simpler than LSTMs, with fewer gates.\n",
    "\n",
    "### Key Components\n",
    "\n",
    "#### 1. Update Gate\n",
    "- Determines how much of the past information (from previous time steps) needs to be passed along to the future.\n",
    "- Balances between the old information (previous hidden state) and the new candidate information.\n",
    "\n",
    "#### 2. Reset Gate\n",
    "- Decides how much of the past information to forget.\n",
    "- Helps the model to decide how much of the past information is irrelevant for the future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operations\n",
    "\n",
    "- **Combining Information**: The update gate helps the GRU to capture dependencies over various time scales.\n",
    "- **Memory Content**: The reset gate allows the GRU to drop any irrelevant information in the future, effectively resetting the memory.\n",
    "\n",
    "## Advantages\n",
    "\n",
    "- **Efficiency**: Generally requires fewer computational resources than LSTM.\n",
    "- **Performance**: Often performs on par with LSTM, especially in smaller datasets or less complex tasks.\n",
    "\n",
    "GRUs are effective for various sequence modeling tasks, including language modeling, speech recognition, and time series analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Building a $\\texttt{GRU}$ layer\n",
    "\n",
    "**Note**: The default activation of this layer is the hyperbolic tangent (and not linear, as with many layers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 4)\n",
      "(32, 5, 4)\n",
      "(32, 4)\n"
     ]
    }
   ],
   "source": [
    "nb_input_features = 10\n",
    "nb_timesteps = 5\n",
    "nb_nodes = 4\n",
    "batch=32\n",
    "inputs = tf.random.normal([batch, nb_timesteps, nb_input_features])\n",
    "gru = tf.keras.layers.GRU(units= nb_nodes)\n",
    "output = gru(inputs)\n",
    "print(output.shape)\n",
    "\n",
    "gru = tf.keras.layers.GRU(4, return_sequences=True, return_state=True)\n",
    "whole_sequence_output, final_state = gru(inputs)\n",
    "print(whole_sequence_output.shape)\n",
    "\n",
    "print(final_state.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_2 (GRU)                 (None, 4)                 192       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 192\n",
      "Trainable params: 192\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Number of trainable parameters = 192\n"
     ]
    }
   ],
   "source": [
    "nb_input_features = 10\n",
    "nb_timesteps = 5\n",
    "nb_nodes = 4\n",
    "\n",
    "gru_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.GRU(nb_nodes, \n",
    "                        input_shape=(nb_timesteps, nb_input_features))\n",
    "]) # depends on whether reset_after is True or False! If False, will substract 3 * nb_nodes parameters.\n",
    "\n",
    "gru_model.summary()\n",
    "\n",
    "print(f'Number of trainable parameters = \n",
    "      {3 * (nb_input_features + nb_nodes + 2) * nb_nodes}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bidirectional recurrent layers\n",
    "\n",
    "When we think of sequences, we think of reading them in a forward fashion (from start to end).\n",
    "\n",
    "In many cases, this makes perfect sense, as the last information is often the most important.\n",
    "\n",
    "However, in some cases the start of a sequence may be as - or even more - important as its end.\n",
    "\n",
    "This is, for example, the case when reading a text. The start may be as important - or even more important - than the end. However, if we feed a sequence in forward, it is difficult to retain this initial information.\n",
    "\n",
    "For this reason, some RNNs read sequences backward. But we do not have to choose between these approaches exclusively - we can use *both* directions at one. This is known as a bidirectional layer. It is simply two seperate layers (one forward, one backward) that are then merged (**suggestion**: Try to use the functional API to implement a bidirectional layer as an exercise)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"./graphics/figure_6-25.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n",
    "Source: \"DLWP\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Building a bidirectional layer\n",
    "\n",
    "... will result in twice as many parameters as normally, since we now use two of each recurrent layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional (Bidirectiona  (None, 8)                480       \n",
      " l)                                                              \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 480\n",
      "Trainable params: 480\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Number of trainable parameters = 480\n"
     ]
    }
   ],
   "source": [
    "nb_input_features = 10\n",
    "nb_timesteps = 5\n",
    "nb_nodes = 4\n",
    "\n",
    "bidirectional_concat_lstm_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(nb_nodes), \n",
    "                                  input_shape=(nb_timesteps,\n",
    "                                               nb_input_features)), \n",
    "])\n",
    "\n",
    "bidirectional_concat_lstm_model.summary()\n",
    "\n",
    "print(f'Number of trainable parameters = \n",
    "      {2 * 4 * (nb_input_features + nb_nodes + 1) * nb_nodes}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can also use addition to merge layers (or some other method, such as multiplication).\n",
    "\n",
    "This does not change the number of parameters of the layer, but does change the number of outputs - which is turn may change the number of parameters of some of the *other* layers of your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_1 (Bidirectio  (None, 4)                480       \n",
      " nal)                                                            \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 480\n",
      "Trainable params: 480\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "bidirectional_add_lstm_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(nb_nodes), merge_mode='sum', input_shape=(nb_timesteps, nb_input_features)), \n",
    "])\n",
    "\n",
    "bidirectional_add_lstm_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Common types of RNN networks\n",
    "<img src=\"./graphics/onetomanyetc.jpeg\" alt=\"Drawing\" style=\"width: 1000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Common types of RNN networks:\n",
    "\n",
    "- One to one: Classification of images\n",
    "- One to many: Generation of text\n",
    "- Many to one: Sentiment anlysis\n",
    "- Many to many: Translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Multiple recurrent layers\n",
    "\n",
    "In some cases, we may want to stack multiple recurrent layers after each other.\n",
    "\n",
    "In these cases, we need to pass along the entire sequence to the next layer (and not just the output of the last step of the sequence).\n",
    "\n",
    "This is done by setting the argument **return_sequences** of a recurrent layer to **True**. As such, this needs to be done for each recurrent layer aside from the last (where we are only interested in the last time step, and as such no longer need the entire sequence).\n",
    "\n",
    "Also, we may mix different types of recurrent layers (although typically this is not done)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Multiple recurrent layers\n",
    "<img src=\"./graphics/deepRNN.png\" alt=\"Drawing\" style=\"width: 1000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Building an RNN with multiple recurrent layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_1 (LSTM)               (None, 5, 4)              240       \n",
      "                                                                 \n",
      " gru_3 (GRU)                 (None, 5, 3)              81        \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 4)                24        \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 350\n",
      "Trainable params: 350\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nb_input_features = 10\n",
    "nb_timesteps = 5;   nb_nodes_1 = 4; nb_nodes_2 = 3; nb_nodes_3 = 2\n",
    "\n",
    "deep_rnn_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.LSTM(nb_nodes_1, input_shape=(nb_timesteps, nb_input_features), return_sequences=True),\n",
    "    tf.keras.layers.GRU(nb_nodes_2, return_sequences=True),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.SimpleRNN(nb_nodes_3)),\n",
    "    tf.keras.layers.Dense(1), # maybe we want to perform regression, where this might be the final layer\n",
    "])\n",
    "\n",
    "deep_rnn_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exercise\n",
    "\n",
    "1. Build three RNNs which take as input a sequence of length 5 with 20 features, uses a single recurrent layer with 20 nodes with a $\\texttt{ReLU}$ activation function, and then uses a $\\texttt{Dense}$ layer to perform classification of 10 classes. Use $\\texttt{SimpleRNN}$, $\\texttt{LSTM}$, and $\\texttt{GRU}$ for the recurrent layers (hence 3 total models). What is the number of parameters in each of the 3 cases?\n",
    "1. Modify your models fom **1.** using $\\texttt{Bidirectional}$ layers. Do this for (at least) the merging methods $\\texttt{concat}$ and $\\texttt{sum}$. What is the number of parameters in each of the 6 cases?\n",
    "1. Modify your models from **1.** by using a *second* recurrent layer (of the same type, so still 3 total models) with 10 nodes. What is the number of parameters in each of the 3 cases?\n",
    "\n",
    "**Hint**: You may use the notebook I have uploaded under this lecture as a starting point (exercise-rnn.ipynb). It provides some of the code, and you then have to fill in the rest. You do not have to use it - it is there if you think it might be helpful!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Working with text data\n",
    "\n",
    "A common use of RNNs is to analyze text data. However, it is not obvious how to work with text data.\n",
    "\n",
    "Note that the consideration here is not directly related to RNNs, but just as with any model, considerations of how to prepare the data are crucial. Indeed, if we tried to solve our task at hand using another method than an RNN, these considerations are also valid!\n",
    "\n",
    "If we forecast sales each day, each day is the obvious observational unit to work with. However, we can think of different ways to structure text data. We could split it into sentences, words, or even characters. Each of these options have advantages and disadvantages.\n",
    "\n",
    "1. Sentence: Not very \"flexible\" - can only generate sentences from the training data! But the quality of a sentence is quite high.\n",
    "2. Word: Middle-ground - and one of the most often used methods. Model outputs words from the training data, but this is often \"enough\" to provide sufficient flexibility and at the same time not reinvent the wheel.\n",
    "3. Character: Very flexible, but the model now needs to learn to spell individual words, and the output can be complete gibberish (not even bad English but not English at all)!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## More details on text data\n",
    "\n",
    "Neural networks work on numbers - not text. So we need some way to represent text data - here in this example in the form of words - using numbers.\n",
    "\n",
    "There are two very common methods:\n",
    "1. An old, but still occasionally useful, method is *n*-grams of words.\n",
    "1. A more modern, and *much* more powerful, method is to use one-hot encoding/hashing and then build embeddings on these."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## *n*-grams of words (bag of words)\n",
    "\n",
    "Think of the sentence \"the cat sat on the mat\". \n",
    "\n",
    "We can construct sub-sentences of at most length *n*. Extracting all these sub-sentences gives the *n*-gram of the sentence.\n",
    "\n",
    "**Set of 2-grams**: {the cat, cat sat, sat on, on the, the mat, the, cat, sat, on the, mat}.\n",
    "\n",
    "**Set of 3-grams**: {the cat sat, cat sat on, sat on the, on the mat, the cat, cat sat, sat on, on the, the mat, the, cat, sat, on the, mat}.\n",
    "\n",
    "However, this is not very informative, as it isn't even order-preserving and further, if large *n* and long sentences are used the sets become quite large. Still useful for shallow learning, but not so much for deep learning.\n",
    "\n",
    "**Note**: *n*-grams also work on the character level (or sentence level, for that matter - any level, in fact)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of vacabulary: 11\n",
      "vocabulary: ['[UNK]' 'the' 'the mat' 'the cat' 'sat on' 'sat' 'on the' 'on' 'mat'\n",
      " 'cat sat' 'cat']\n",
      "[UNK]\n",
      "[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "the\n",
      "[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "the mat\n",
      "[0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]\n",
      "the cat\n",
      "[0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]\n",
      "sat on\n",
      "[0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0]\n",
      "sat\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "on the\n",
      "[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0]\n",
      "on\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]\n",
      "mat\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]\n",
      "cat sat\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0]\n",
      "cat\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "text    = [\"the cat sat on the mat\"]\n",
    "encoder = tf.keras.layers.TextVectorization(ngrams=2,max_tokens=100,\n",
    "                                            output_mode=\"multi_hot\")\n",
    "encoder.adapt(text) # Computes a vocabulary of string terms from tokens in a dataset.\n",
    "vocab   = np.array(encoder.get_vocabulary()) # Get and print the vocabulary\n",
    "print(f'length of vacabulary: {len(vocab)}')\n",
    "print(f'vocabulary: {vocab}')\n",
    "encoded_example = []\n",
    "for ngram in vocab:\n",
    "    print(ngram)\n",
    "    print(list(encoder(ngram).numpy()))\n",
    "    encoded_example.append(list(encoder(ngram).numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transforming the bag of words to a matrix:\n",
      "\n",
      "[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]\n",
      "[0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "print('transforming the bag of words to a matrix:\\n', \n",
    "      *encoded_example,sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## One-hot encoding (hashing) and word embeddings\n",
    "\n",
    "A much more common way to use text data is to use one-hot encoding (hashing) and word embeddings. \n",
    "\n",
    "Contrary to bag-of-words this allow us to model text as a sequence.\n",
    "\n",
    "This is simply building a dictionary for each word (or more generally token, it could be the character level).\n",
    "\n",
    "For example, we may build the following dictionary for our earlier example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## One-hot encoding (hashing)\n",
    "\n",
    "Hash function is a function that can be used to map data of arbitrary size to data of fixed size\n",
    "\n",
    "<img src=\"./graphics/hashing.jpg\" alt=\"Drawing\" style=\"width: 1000px;\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 0, 4]\n"
     ]
    }
   ],
   "source": [
    "## Hashing\n",
    "one_hot_dict = {\n",
    "    'the': 0,\n",
    "    'cat': 1,\n",
    "    'sat': 2,\n",
    "    'on': 3,\n",
    "    'mat': 4,\n",
    "}\n",
    "\n",
    "numerical_encoded_sentence = [one_hot_dict[word] \n",
    "                              for word in 'the cat sat on the mat'.split(' ')]\n",
    "print(numerical_encoded_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## One-hot encoding\n",
    "\n",
    "Then, we use one-hot encoding of the numerical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(tf.keras.utils.to_categorical(numerical_encoded_sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## From raw text to vectors\n",
    "\n",
    "<img src=\"./graphics/fromrawtexttovectors.PNG\" alt=\"Drawing\" style=\"width: 1000px;\"/>\n",
    "Source: \"DLWP\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Embedding\n",
    "\n",
    "One-hot encoding is *sparse*. This is particularly true if there are many classes.\n",
    "\n",
    "In text data working at the word level, there are a TON (often many thousands) of classes. Hence each input consists of a vector with one 1 and many 0's.\n",
    "\n",
    "However, words are *related*, and we can often store them much more efficiently. Embedding is one such way, in which a sparse vector is transformed to a (often much smaller) non-sparse vector. In this more dense space, we often see that words such as \"lion\" and \"tiger\" might be closer to each other than to \"car\".\n",
    "\n",
    "For a problem with *n* words (or tokens, in the general case) and an embedding dimension *k*, the embedding function is a function $f: \\{0, 1\\}^n \\rightarrow \\mathbb{R}^k$.\n",
    "\n",
    "As such, an embedding is \"just\" a lookup table, \"looking up\" *k* real numbers for each word.\n",
    "\n",
    "How to find these numbers? Typically just a part of the neural network. Pre-trained versions are also availble."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## From one-hot to embeddings\n",
    "\n",
    "<img src=\"./graphics/06fig02.jpg\" alt=\"Drawing\" style=\"width: 800px;\"/>\n",
    "Source: \"DLWP\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## From one-hot to embeddings\n",
    "\n",
    "<img src=\"./graphics/figure_6-1.png\" alt=\"Drawing\" style=\"width: 800px;\"/>\n",
    "Source: \"DLWP\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Embeddings may be interpretable\n",
    "\n",
    "### Leading example: \"King\" - \"Man\" + \"Woman\" = \"Queen\"\n",
    "\n",
    "### Visualization (clustering)\n",
    "\n",
    "<img src=\"./graphics/figure_6-3.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n",
    "\n",
    "\n",
    "Source: \"DLWP\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Building $\\texttt{Embedding}$ layers and vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
    "\n",
    "reviews = ['nice food',\n",
    "        'amazing restaurant',\n",
    "        'too good',\n",
    "        'just loved it!',\n",
    "        'will go again',\n",
    "        'horrible food',\n",
    "        'never go there',\n",
    "        'poor service',\n",
    "        'poor quality',\n",
    "        'needs improvement']\n",
    "sentiment = np.array([1,1,1,1,1,0,0,0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 3]\n",
      "[1, 3]\n",
      "Is there a problem?...collisions?\n",
      "\n",
      "Trying with a larger vocabulary\n",
      "[30, 18]\n",
      "[28, 36]\n"
     ]
    }
   ],
   "source": [
    "vocabulary_size = 4\n",
    "print(one_hot(\"nice food\",vocabulary_size))\n",
    "print(one_hot(\"amazing restaurant\",vocabulary_size))\n",
    "print(\"Is there a problem?...collisions?\")\n",
    "\n",
    "print(\"\")\n",
    "print(\"Trying with a larger vocabulary\")\n",
    "vocabulary_size = 40 #75\n",
    "print(one_hot(\"nice food\",vocabulary_size))\n",
    "print(one_hot(\"amazing restaurant\",vocabulary_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one hot encoding/hashing: [[30, 18], [28, 36], [31, 27], [16, 23, 28], [6, 14, 4], [1, 18], [38, 14, 26], [5, 17], [5, 4], [32, 23]]\n",
      "Any collisions?\n"
     ]
    }
   ],
   "source": [
    "encoded_reviews = [one_hot(d, vocabulary_size) for d in reviews]\n",
    "print(f'one hot encoding/hashing: {encoded_reviews}')\n",
    "print(\"Any collisions?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one hot encoding/hashing: [[30 18  0  0]\n",
      " [28 36  0  0]\n",
      " [31 27  0  0]\n",
      " [16 23 28  0]\n",
      " [ 6 14  4  0]\n",
      " [ 1 18  0  0]\n",
      " [38 14 26  0]\n",
      " [ 5 17  0  0]\n",
      " [ 5  4  0  0]\n",
      " [32 23  0  0]]\n"
     ]
    }
   ],
   "source": [
    "max_length = 4\n",
    "padded_reviews = pad_sequences(encoded_reviews, maxlen=max_length, padding='post')\n",
    "print(f'one hot encoding/hashing: {padded_reviews}')\n",
    "\n",
    "#Note that there can be a \"collision\": Some words are encoded with the same integer!!\n",
    "#Increasing the vocabulary will reduce the likelihood of a collision...but what are\n",
    "#the effects of this downstream?..a lager embedding layer/matrix?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of vacabulary: 22\n",
      "one hot encoding/hashing: ['nice food', 'amazing restaurant', 'too good', 'just loved it!', 'will go again', 'horrible food', 'never go there', 'poor service', 'poor quality', 'needs improvement']\n",
      "one hot encoding/hashing:\n",
      " [[11  4  0  0]\n",
      " [20  9  0  0]\n",
      " [ 6 19  0  0]\n",
      " [15 14 16  0]\n",
      " [ 5  3 21  0]\n",
      " [18  4  0  0]\n",
      " [12  3  7  0]\n",
      " [ 2  8  0  0]\n",
      " [ 2 10  0  0]\n",
      " [13 17  0  0]]\n"
     ]
    }
   ],
   "source": [
    "#Approach that eliminate collisions without increasing the vocabulary\n",
    "MAX_VOCAB_SIZE = 40\n",
    "encoder = tf.keras.layers.TextVectorization(\n",
    "    max_tokens=MAX_VOCAB_SIZE)\n",
    "encoder.adapt(reviews)\n",
    "vocab = np.array(encoder.get_vocabulary())\n",
    "print(f'length of vacabulary: {len(vocab)}')\n",
    "\n",
    "encoded_example = encoder(reviews).numpy()\n",
    "max_length = 4\n",
    "padded_reviews = pad_sequences(encoded_example, maxlen=max_length,\n",
    "                               padding='post')\n",
    "print(f'one hot encoding/hashing: {reviews}')\n",
    "print(f'one hot encoding/hashing:\\n {padded_reviews}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bulding a simple model with an embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "embedding_dimension = 5\n",
    "embedding_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=len(vocab), output_dim=embedding_dimension,\n",
    "                             input_length=max_length,name=\"embedding\"),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 4, 5)              110       \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 20)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 131\n",
      "Trainable params: 131\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "embedding_model.compile(optimizer='adam', loss='binary_crossentropy', \n",
    "                        metrics=['accuracy'])\n",
    "print(embedding_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Defining input and output and fitting/evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "X = padded_reviews\n",
    "y = sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x29c7c3b3670>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_model.fit(X, y, epochs=50, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 210ms/step - loss: 0.6269 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "loss, accuracy = embedding_model.evaluate(X, y)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Comparing the estimated word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Horrible: [ 0.04541338 -0.02032448  0.01450942  0.09498853  0.07235244]\n",
      "Poor: [ 0.02196703 -0.09323229  0.03048165  0.04725321  0.04861407]\n",
      "Nice: [-0.02132252  0.08659092 -0.03001419 -0.09454425 -0.03538161]\n",
      "Amazing: [-0.00172583  0.05351468 -0.03273857 -0.08425601 -0.08209368]\n"
     ]
    }
   ],
   "source": [
    "weights =embedding_model.get_layer('embedding').get_weights()[0]\n",
    "#Horrible\n",
    "print(f'Horrible: {weights[padded_reviews[5][0]]}')\n",
    "#Poor\n",
    "print(f'Poor: {weights[padded_reviews[7][0]]}')\n",
    "#Good\n",
    "print(f'Nice: {weights[padded_reviews[0][0]]}')\n",
    "#Amazing\n",
    "print(f'Amazing: {weights[padded_reviews[1][0]]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Building a model with embeddings and recurrent layers\n",
    "\n",
    "Let us try to combine embedding layers and recurrent layers. This is often the basic structure of successful RNNs for text data.\n",
    "\n",
    "In this example, we will imagine that there are $1000$ possible words in our lookup, we will condense these to 128 dimensions (this is the embedding dimension), we will then use a recurrent layer with $64$ nodes, and finally a fully connected layer with $10$ nodes and a softmax activation function (imagine this is a classification problem with $10$ classes).\n",
    "\n",
    "Such a network will have 165,898 parameters, since:\n",
    "1. Embedding layer associate 128 numbers with each of 1000 words = 128,000 parameters.\n",
    "1. The recurrent layer chosen is GRU, which will have 128 inputs and 64 outputs. Using our earlier formula, this is $3(128 + 64 + 2)64=37,248$.\n",
    "1. The fully connected layer will have 64 inputs and 10 outputs, and $64\\cdot10+10=650$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## A recurrent model with an embedding layer\n",
    "\n",
    "The below model would serve as a decent starting point for many problems related to text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 128)         128000    \n",
      "                                                                 \n",
      " gru_4 (GRU)                 (None, 64)                37248     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 165,898\n",
      "Trainable params: 165,898\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=1000, output_dim=128),\n",
    "    tf.keras.layers.GRU(64),\n",
    "    tf.keras.layers.Dense(10, activation='softmax'),\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The embedding layer architecture\n",
    "\n",
    "<img src=\"./graphics/Emded 3 Middle.png\" alt=\"Drawing\" style=\"width: 1000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exercise\n",
    "\n",
    "1. Use the IMDB movie review data (positive/negative movie reviews) to build a model that is able to predict the sentiment (positive/negative) from movie reviews. Your initial model should use one embedding layer, one recurrent layer (up to you which type), and a final fully connected layer to perform the classification.\n",
    "1. Try to improve your model by doing (at least) the following: add an additional recurrent layer and/or use a bidirectional recurrent layer (**note**: If you have a good 1-layer model this may be difficult - just try your best).\n",
    "1. In the preprocessing of the data made by me, I kepts the top 1000 words and let all reviews be 100 words long. Consider changing one/both of these to try to improve your best model (**hint**: the limit of only 100 words is very severe - try doubling it to 200, this may likely improve your performance).\n",
    "\n",
    "**Hint**: You may use the notebook I have uploaded under this lecture as a starting point (exercise-imdb.ipynb). It provides some of the code, and you then have to fill in the rest. You do not have to use it - it is there if you think it might be helpful!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Special considerations for RNNs - dropout\n",
    "\n",
    "Remember how we used some layers differently for CNNs (such as dropout)? Not because it was needed, or even necessarily better, but because there might be cases where the \"normal\" version works in some unexpected way (which may be detrimental), such as dropout not performing strong regularization if adjacent pixels are highly correlated.\n",
    "\n",
    "It turns out that such differences are also occasionally warranted for RNNs - and once again dropout is such a case.\n",
    "\n",
    "First, we may ask: **where** do we even apply dropout? We now have two candidates - the input units and the recurrent units.\n",
    "\n",
    "Here, one answer would be *both* places. But as it turns out (see next slide), recurrent dropout may be prohibitively slow.\n",
    "\n",
    "Second, we may ask **how** do we apply dropout? It turns out that fixing the dropout mask along the time-dimension for each forward pass is often helpful (TensorFlow easily handles this).\n",
    "\n",
    "Great blog: https://adriangcoder.medium.com/a-review-of-dropout-as-applied-to-rnns-72e79ecd5b7b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Special considerations for RNNs - dropout\n",
    "\n",
    "### Dropout on input units\n",
    "\n",
    "<img src=\"./graphics/dropout_simple.JPG\" alt=\"Drawing\" style=\"width: 1000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Special considerations for RNNs - dropout\n",
    "\n",
    "### Dropout on recurrent units\n",
    "\n",
    "<img src=\"./graphics/dropout_lstm.JPG\" alt=\"Drawing\" style=\"width: 1000px;\"/>\n",
    "\n",
    "**Note**: tf is based on \"ours\" described in https://arxiv.org/abs/1603.05118"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Special considerations for RNNs - \"hardware acceleration\"\n",
    "\n",
    "In order to make use of optimized implementations of recurrent layers in TensorFlow, a number of conditions has to be met.\n",
    "\n",
    "To see the full list, look specifically at the documentation of specific layers:\n",
    "1. https://www.tensorflow.org/api_docs/python/tf/keras/layers/SimpleRNN\n",
    "1. https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM\n",
    "1. https://www.tensorflow.org/api_docs/python/tf/keras/layers/GRU\n",
    "\n",
    "In general, however, there are two \"easy\" ways to break the rules required for efficient implementations:\n",
    "1. You may be tempted to change the activation function (i.e. to ReLU). This often results in heavy slowdowns, however, so I recommend keeping the hyperbolic tangent (on my computer, this can easily make a model 30 times slower!).\n",
    "1. Using recurrent dropout (i.e. applying dropout to the recurrent state). This often results in heavy slowdowns (on my computer, this can easily make a model 50 times slower!)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Convolutional layers for sequential data\n",
    "\n",
    "Recall how I briefly mentioned that convolutional layers could also be used for non-image data?\n",
    "\n",
    "One such case is sequential data, where 1D convolutions are sometimes very helpful.\n",
    "\n",
    "A great benefit is that these models are often blazingly fast compared to recurrent models (which are notoriously slow), while still explicitly using parameter sharing to handle sequential data.\n",
    "\n",
    "They are also much easier to train.\n",
    "\n",
    "Note, however, that if we want to learn from a very long sequence where the entire sequence is needed for understanding, we need very wide kernels and/or many convolutions after each other.\n",
    "\n",
    "However, kernels may also be much larger, since they are now vectors rather than matrices (i.e. a kernel of length 9 has as many parameters as a 2D kernel of size (3, 3)).\n",
    "\n",
    "Further, pooling may still be used (which significantly helps in handling long sequences)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 1D convolutions\n",
    "\n",
    "*Note that pooling works similarly, but without with a dot product of parameters but rather the specific operation specified (whether max, average, or something else - depends on the type of pooling).*\n",
    "\n",
    "<img src=\"./graphics/Architecture-overview-of-the-CNN-model.png\" alt=\"Drawing\" style=\"width: 1000px;\"/>\n",
    "Source: \"DLWP\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## A convolutional model for sequence data...\n",
    "\n",
    "... here combined with an embedding layer, which is often done for text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 5)           50        \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, None, 32)          512       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 562\n",
      "Trainable params: 562\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocabulary_size = 10\n",
    "embedding_dimension = 5\n",
    "\n",
    "cnn_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=vocabulary_size, \n",
    "                              output_dim=embedding_dimension),\n",
    "    tf.keras.layers.Conv1D(filters=32, kernel_size=3, activation='relu')\n",
    "])\n",
    "\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Combining convolutional and recurrent layers\n",
    "\n",
    "There is no barrier to combining convolutional and recurrent layers.\n",
    "\n",
    "Indeed, this may make a lot of sense. Typically, this will be done by starting by applying convolutional (and maybe pooling) layers to shorten a sentence, and then apply recurrent layers to the shorter sentence. \n",
    "\n",
    "Intutitively (*but always be cautious when making such interpretations*), this works by first combining neighboring words into a new, smaller set of features (i.e. \"summarizing\" a part of a sentence), and then applying a a recurrent neural network to interpret the sequence of these new features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "\n",
    "<img src=\"./graphics/figure_6-30.png\" alt=\"Drawing\" style=\"width: 800px;\"/>\n",
    "Source: \"DLWP\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## A convolutional recurrent model for sequence data...\n",
    "\n",
    "... here combined with an embedding layer, which is often done for text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, None, 5)           50        \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, None, 32)          512       \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 16)                2400      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,962\n",
      "Trainable params: 2,962\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocabulary_size = 10\n",
    "embedding_dimension = 5\n",
    "\n",
    "cnn_rnn_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=vocabulary_size, \n",
    "                              output_dim=embedding_dimension),\n",
    "    tf.keras.layers.Conv1D(filters=32, kernel_size=3, activation='relu'),\n",
    "    tf.keras.layers.GRU(units=16),\n",
    "])\n",
    "\n",
    "cnn_rnn_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exercise\n",
    "\n",
    "1. Try to improve your model from the earlier IMDB exercise by using some of the optimization and regularization tricks you know (for example, try dropout, early stopping, and weight regularization - there are many things to potentially try!).\n",
    "1. Attempt to solve the IMDB classification task using a convolutional neural network.\n",
    "1. Build a model which combines convolutional and recurrent layers to solve thr IMDB classification task.\n",
    "\n",
    "**Hint**: You may use the notebook I have uploaded under this lecture as a starting point (exercise-imdb-2.ipynb). It provides some of the code, and you then have to fill in the rest. You do not have to use it - it is there if you think it might be helpful!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## An introduction to generative models\n",
    "\n",
    "We now have all the pieces needed to do something brand new - instead of focusing on classification or regression$^1$, which is what we have mostly been doing, we can start to *generate* new data.\n",
    "\n",
    "Specifically, we will build an RNN to generate text by using Shakespear plays. We will start *from scratch*, in the sense of loading a text file of raw text. Think of what this means: you can use an entirely similar approach for any text data you can imagine!\n",
    "\n",
    "The exact implementation can still be done in many ways, but for this example, we will:\n",
    "1. Use the text at the character level (instead of our current examples, which were built at the word level).\n",
    "2. Use an embedding layer.\n",
    "3. Use a GRU layer.\n",
    "4. Use a dense layer (for character classification).\n",
    "\n",
    "**Note**: This draws heavily from https://www.tensorflow.org/tutorials/text/text_generation, but I have tried to explain some additional stuff.\n",
    "\n",
    "$^1$As will become apparent, we actually still perform classification to train our model in the first place."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Graphic illustration\n",
    "\n",
    "Putting everything together, we will end up with something like:\n",
    "<img src=\"./graphics/text_generation_training.png\" alt=\"Drawing\" style=\"width: 800px;\"/>\n",
    "Source: https://www.tensorflow.org/tutorials/text/text_generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# We load the data from the web\n",
    "path_to_file = tf.keras.utils.get_file('shakespeare.txt', \n",
    "                                       'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 1115394 characters\n"
     ]
    }
   ],
   "source": [
    "# Read and decode (to get \\n to \"enter\")\n",
    "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
    "# length of text is the number of characters in it\n",
    "print(f'Length of text: {len(text)} characters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Take a look at the first 250 characters in text\n",
    "print(text[:250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65 unique characters\n",
      "['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', '3', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "# The unique characters in the file\n",
    "vocab = sorted(set(text))\n",
    "print (f'{len(vocab)} unique characters')\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'\\n': 0, ' ': 1, '!': 2, '$': 3, '&': 4, \"'\": 5, ',': 6, '-': 7, '.': 8, '3': 9, ':': 10, ';': 11, '?': 12, 'A': 13, 'B': 14, 'C': 15, 'D': 16, 'E': 17, 'F': 18, 'G': 19, 'H': 20, 'I': 21, 'J': 22, 'K': 23, 'L': 24, 'M': 25, 'N': 26, 'O': 27, 'P': 28, 'Q': 29, 'R': 30, 'S': 31, 'T': 32, 'U': 33, 'V': 34, 'W': 35, 'X': 36, 'Y': 37, 'Z': 38, 'a': 39, 'b': 40, 'c': 41, 'd': 42, 'e': 43, 'f': 44, 'g': 45, 'h': 46, 'i': 47, 'j': 48, 'k': 49, 'l': 50, 'm': 51, 'n': 52, 'o': 53, 'p': 54, 'q': 55, 'r': 56, 's': 57, 't': 58, 'u': 59, 'v': 60, 'w': 61, 'x': 62, 'y': 63, 'z': 64}\n"
     ]
    }
   ],
   "source": [
    "# Creating a mapping from unique characters to indices\n",
    "char2idx = {unique_char: idx for idx, unique_char in enumerate(vocab)}\n",
    "print(char2idx)\n",
    "\n",
    "# And convert the entire text to integers (corrosponding to characters \n",
    "#using the mapping above.)\n",
    "idx2char = np.array(vocab)\n",
    "text_as_int = np.array([char2idx[char] for char in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen ---- characters mapped to int ---- > [18 47 56 57 58  1 15 47 58 47 64 43 52]\n"
     ]
    }
   ],
   "source": [
    "# Show how the first 13 characters from the text are mapped to integers\n",
    "print('{} ---- characters mapped to int ---- > {}'.format(text[:13], text_as_int[:13]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Now to get the data in a format for the network\n",
    "\n",
    "So far so good - we have the data *as well* as a representation for the data using integers. This is great!\n",
    "\n",
    "The next steps prepares the data optimally for a (recurrent) neural network and are somewhat advanced..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 ---- corresponds to ---- > F\n",
      "47 ---- corresponds to ---- > i\n",
      "56 ---- corresponds to ---- > r\n",
      "57 ---- corresponds to ---- > s\n",
      "58 ---- corresponds to ---- > t\n"
     ]
    }
   ],
   "source": [
    "# The maximum length sentence we want for a single input in characters\n",
    "seq_length = 100\n",
    "examples_per_epoch = len(text) // (seq_length + 1)\n",
    "\n",
    "# Create training examples / targets: \n",
    "# tf.data.Dataset.from_tensor_slices converts numpy into tf.data\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
    "\n",
    "# Let us print the first 5 characters. Notice they spell \"First\", as they should!\n",
    "for idx in char_dataset.take(5):\n",
    "    print(f'{idx.numpy()} ---- corresponds to ---- > {idx2char[idx.numpy()]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of batch 1 is (101,) and writes:\n",
      "--------\n",
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You \n",
      "--------\n",
      "--------\n",
      "Length of batch 2 is (101,) and writes:\n",
      "--------\n",
      "are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you k\n",
      "--------\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "# We have the characters - now we want to create sequences. \n",
    "# Remember seq_length = 100 here! This can be tuned\n",
    "# We drop the remainder to ensure all sequences are equally long.\n",
    "sequences = char_dataset.batch(seq_length + 1, drop_remainder=True)\n",
    "\n",
    "# Let's print the furst 2 batches - each of length 101. Why 101 and not 100?? \n",
    "# This is since we want to predict the next word.\n",
    "# For this, we will later (next slide) split this into 2 chunks, \n",
    "#one with words 1:100 and one with words 2:101 (both length 100).\n",
    "for jter,item in enumerate(sequences.take(2)):\n",
    "    print(f'Length of batch {jter+1} is {item.numpy().shape} and writes:')    \n",
    "    print('--------')\n",
    "    print(''.join(idx2char[item.numpy()]))\n",
    "    print('--------')    \n",
    "    print('--------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset element_spec=(TensorSpec(shape=(100,), dtype=tf.int32, name=None), TensorSpec(shape=(100,), dtype=tf.int32, name=None))>\n"
     ]
    }
   ],
   "source": [
    "# Now we split the sequences into the input for the network and the output \n",
    "#(target) of the network!\n",
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1] # 1:100\n",
    "    target_text = chunk[1:] # 2:101\n",
    "\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = sequences.map(split_input_target)\n",
    "print(dataset) # input and output 100 long now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data:  'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'\n",
      "Target data: 'irst Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n",
      "Input data:  'are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you '\n",
      "Target data: 're all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you k'\n"
     ]
    }
   ],
   "source": [
    "# Let us print just the first 2 examples. See how the target is \"shifted\" 1 character!\n",
    "for input_example, target_example in  dataset.take(2):\n",
    "    print('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n",
    "    print('Target data:', repr(''.join(idx2char[target_example.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step_ 0\n",
      "  Input:          39 ('a')\n",
      "  Target output:  56 ('r')\n",
      "Step_ 1\n",
      "  Input:          56 ('r')\n",
      "  Target output:  43 ('e')\n",
      "Step_ 2\n",
      "  Input:          43 ('e')\n",
      "  Target output:  1 (' ')\n",
      "Step_ 3\n",
      "  Input:          1 (' ')\n",
      "  Target output:  39 ('a')\n",
      "Step_ 4\n",
      "  Input:          39 ('a')\n",
      "  Target output:  50 ('l')\n"
     ]
    }
   ],
   "source": [
    "# Below we showcase how the individual input/outputs to the network look. \n",
    "#Remember the first word is \"are\"!\n",
    "for i, (input_idx, target_idx) in enumerate(zip(input_example[:5], target_example[:5])):\n",
    "    print(f\"Step_ {i}\")\n",
    "    print(\"  Input:          {} ({:s})\".format(input_idx, repr(idx2char[input_idx])))\n",
    "    print(\"  Target output:  {} ({:s})\".format(target_idx, repr(idx2char[target_idx])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int32, name=None), TensorSpec(shape=(64, 100), dtype=tf.int32, name=None))>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now for the batch size - 64 here. That is, each minibatch consists of 64 sequences, \n",
    "#each of 100 characters!\n",
    "batch_size = 64\n",
    "\n",
    "# Buffer size to shuffle the dataset\n",
    "# (TF data is designed to work with possibly infinite sequences,\n",
    "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
    "# it maintains a buffer in which it shuffles elements).\n",
    "buffer_size = 10000\n",
    "\n",
    "# Note how we drop the remainder here - otherwise not all batches are exactly 64 long.\n",
    "dataset = dataset.shuffle(buffer_size).batch(batch_size, drop_remainder=True)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Now for some parameters to build the network!\n",
    "vocab_size = len(vocab) # The 65 unique characters defined above\n",
    "\n",
    "# The embedding dimension\n",
    "embedding_dim = 256\n",
    "\n",
    "# Number of RNN units\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# And FINALLY we can build it. Yes, it really is that simple in Keras!\n",
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(\n",
    "            input_dim=vocab_size, \n",
    "            output_dim=embedding_dim,\n",
    "            batch_input_shape=[batch_size, None], \n",
    "            # None allows for different sequence lengths to be used\n",
    "        ),\n",
    "        tf.keras.layers.GRU(\n",
    "            units=rnn_units,\n",
    "            return_sequences=True,\n",
    "            stateful=True,\n",
    "            recurrent_initializer='glorot_uniform',\n",
    "        ),\n",
    "        tf.keras.layers.Dense(vocab_size, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "model = build_model(\n",
    "  vocab_size = vocab_size,\n",
    "  embedding_dim=embedding_dim,\n",
    "  rnn_units=rnn_units,\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (64, None, 256)           16640     \n",
      "                                                                 \n",
      " gru_1 (GRU)                 (64, None, 1024)          3938304   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (64, None, 65)            66625     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,021,569\n",
      "Trainable params: 4,021,569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[12  0 35 ...  5 57  1]\n",
      " [63  1 46 ... 46 47 50]\n",
      " [43  1 51 ... 57 43 52]\n",
      " ...\n",
      " [46  1 58 ... 60 43 57]\n",
      " [39 56  1 ...  6  1 47]\n",
      " [53 53 42 ... 13 30 32]], shape=(64, 100), dtype=int32)\n",
      "(64, 100, 65) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "# Let us test we can perform a forward pass - succes!\n",
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    print(input_example_batch)\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-4.172442  -4.1706777 -4.17662   ... -4.1725254 -4.1558123 -4.168696 ]\n",
      " [-4.1792617 -4.172461  -4.1754208 ... -4.1703706 -4.1631985 -4.1841884]\n",
      " [-4.1662087 -4.155744  -4.1872277 ... -4.1833854 -4.183887  -4.183751 ]\n",
      " ...\n",
      " [-4.1796517 -4.184438  -4.173463  ... -4.160218  -4.1683226 -4.1516323]\n",
      " [-4.177162  -4.181773  -4.172084  ... -4.161225  -4.1751876 -4.1675224]\n",
      " [-4.1922317 -4.1769347 -4.18009   ... -4.1683035 -4.1681237 -4.1680255]], shape=(100, 65), dtype=float32)\n",
      "(100, 1)\n",
      "(100,)\n",
      "sampled indices [62 62  4 54 21 23  8  8 60  3 41 14 21 27 24  3  9 63 50 44  0 14 47 45\n",
      "  4 12 28 22 35 46 54 50 33 12  4 57 49  7 54 41 28 38 10 39 16  6  5 58\n",
      " 54 39 45 11 38  2 39 11 52 25 52  4 58  7 40 35 29 62 33 12 53  7 14 38\n",
      " 45  3 27 39  7 15 47 54  1 43 44 37  8 51  2 41 12 48 45 15 28 38 42  1\n",
      " 37 63 41  1]\n"
     ]
    }
   ],
   "source": [
    "# Just for fun, let us look at how our network performs before we train it.\n",
    "print(tf.math.log(example_batch_predictions)[0])\n",
    "sampled_indices = tf.random.categorical(tf.math.log(example_batch_predictions)[0], \n",
    "                                        num_samples=1)\n",
    "print(sampled_indices.shape)\n",
    "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()\n",
    "print(sampled_indices.shape)\n",
    "\n",
    "print(f'sampled indices {sampled_indices}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: \n",
      " '.\\n\\nVOLUMNIA:\\nSweet madam.\\n\\nVIRGILIA:\\nI am glad to see your ladyship.\\n\\nVALERIA:\\nHow do you both? you '\n",
      "\n",
      "Next Char Predictions: \n",
      " \"wNqxJyfjD\\nL s'UyLJI-gEyNyMD,DWtQqcPSW,H.XMEi3FoU,AiO&jNlT\\nXyh\\nbvc!:Ecv!i;zDotW'csPi!JO&tMSceTKwmJXgq\"\n"
     ]
    }
   ],
   "source": [
    "# Not good! Complete gibberish - but that is expected!\n",
    "print(\"Input: \\n\", repr(\"\".join(idx2char[input_example_batch[0]])))\n",
    "print()\n",
    "print(\"Next Char Predictions: \\n\", repr(\"\".join(idx2char[sampled_indices ])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = 'C:/Users/cmd/Documents'\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "172/172 [==============================] - 45s 248ms/step - loss: 2.6744 - accuracy: 0.2836\n",
      "Epoch 2/50\n",
      "172/172 [==============================] - 44s 248ms/step - loss: 1.9738 - accuracy: 0.4234\n",
      "Epoch 3/50\n",
      "172/172 [==============================] - 44s 249ms/step - loss: 1.7015 - accuracy: 0.4975\n",
      "Epoch 4/50\n",
      "172/172 [==============================] - 44s 249ms/step - loss: 1.5499 - accuracy: 0.5381\n",
      "Epoch 5/50\n",
      "172/172 [==============================] - 44s 250ms/step - loss: 1.4599 - accuracy: 0.5604\n",
      "Epoch 6/50\n",
      "172/172 [==============================] - 45s 250ms/step - loss: 1.3988 - accuracy: 0.5761\n",
      "Epoch 7/50\n",
      "172/172 [==============================] - 45s 250ms/step - loss: 1.3537 - accuracy: 0.5878\n",
      "Epoch 8/50\n",
      "172/172 [==============================] - 44s 250ms/step - loss: 1.3153 - accuracy: 0.5971\n",
      "Epoch 9/50\n",
      "172/172 [==============================] - 44s 249ms/step - loss: 1.2801 - accuracy: 0.6068\n",
      "Epoch 10/50\n",
      "172/172 [==============================] - 44s 248ms/step - loss: 1.2481 - accuracy: 0.6148\n",
      "Epoch 11/50\n",
      "172/172 [==============================] - 45s 248ms/step - loss: 1.2157 - accuracy: 0.6236\n",
      "Epoch 12/50\n",
      "172/172 [==============================] - 45s 250ms/step - loss: 1.1855 - accuracy: 0.6323\n",
      "Epoch 13/50\n",
      "172/172 [==============================] - 45s 250ms/step - loss: 1.1521 - accuracy: 0.6419\n",
      "Epoch 14/50\n",
      "172/172 [==============================] - 45s 250ms/step - loss: 1.1186 - accuracy: 0.6522\n",
      "Epoch 15/50\n",
      "172/172 [==============================] - 45s 251ms/step - loss: 1.0854 - accuracy: 0.6623\n",
      "Epoch 16/50\n",
      "172/172 [==============================] - 45s 249ms/step - loss: 1.0500 - accuracy: 0.6741\n",
      "Epoch 17/50\n",
      "172/172 [==============================] - 45s 249ms/step - loss: 1.0154 - accuracy: 0.6854\n",
      "Epoch 18/50\n",
      "172/172 [==============================] - 45s 251ms/step - loss: 0.9794 - accuracy: 0.6980\n",
      "Epoch 19/50\n",
      "172/172 [==============================] - 46s 252ms/step - loss: 0.9437 - accuracy: 0.7105\n",
      "Epoch 20/50\n",
      "172/172 [==============================] - 46s 253ms/step - loss: 0.9097 - accuracy: 0.7222\n",
      "Epoch 21/50\n",
      "172/172 [==============================] - 46s 251ms/step - loss: 0.8783 - accuracy: 0.7336\n",
      "Epoch 22/50\n",
      "172/172 [==============================] - 45s 251ms/step - loss: 0.8484 - accuracy: 0.7441\n",
      "Epoch 23/50\n",
      "172/172 [==============================] - 45s 251ms/step - loss: 0.8217 - accuracy: 0.7539\n",
      "Epoch 24/50\n",
      "172/172 [==============================] - 45s 251ms/step - loss: 0.7957 - accuracy: 0.7632\n",
      "Epoch 25/50\n",
      "172/172 [==============================] - 45s 251ms/step - loss: 0.7753 - accuracy: 0.7706\n",
      "Epoch 26/50\n",
      "172/172 [==============================] - 46s 251ms/step - loss: 0.7547 - accuracy: 0.7780\n",
      "Epoch 27/50\n",
      "172/172 [==============================] - 45s 251ms/step - loss: 0.7390 - accuracy: 0.7843\n",
      "Epoch 28/50\n",
      "172/172 [==============================] - 45s 250ms/step - loss: 0.7265 - accuracy: 0.7881\n",
      "Epoch 29/50\n",
      "172/172 [==============================] - 45s 250ms/step - loss: 0.7122 - accuracy: 0.7936\n",
      "Epoch 30/50\n",
      "172/172 [==============================] - 45s 250ms/step - loss: 0.6998 - accuracy: 0.7978\n",
      "Epoch 31/50\n",
      "172/172 [==============================] - 45s 251ms/step - loss: 0.6914 - accuracy: 0.8013\n",
      "Epoch 32/50\n",
      "172/172 [==============================] - 46s 250ms/step - loss: 0.6814 - accuracy: 0.8043\n",
      "Epoch 33/50\n",
      "172/172 [==============================] - 45s 251ms/step - loss: 0.6749 - accuracy: 0.8067\n",
      "Epoch 34/50\n",
      "172/172 [==============================] - 45s 250ms/step - loss: 0.6684 - accuracy: 0.8086\n",
      "Epoch 35/50\n",
      "172/172 [==============================] - 45s 250ms/step - loss: 0.6635 - accuracy: 0.8106\n",
      "Epoch 36/50\n",
      "172/172 [==============================] - 45s 251ms/step - loss: 0.6589 - accuracy: 0.8122\n",
      "Epoch 37/50\n",
      "172/172 [==============================] - 45s 249ms/step - loss: 0.6535 - accuracy: 0.8142\n",
      "Epoch 38/50\n",
      "172/172 [==============================] - 45s 250ms/step - loss: 0.6510 - accuracy: 0.8146\n",
      "Epoch 39/50\n",
      "172/172 [==============================] - 45s 249ms/step - loss: 0.6494 - accuracy: 0.8153\n",
      "Epoch 40/50\n",
      "172/172 [==============================] - 45s 251ms/step - loss: 0.6483 - accuracy: 0.8159\n",
      "Epoch 41/50\n",
      "172/172 [==============================] - 45s 250ms/step - loss: 0.6446 - accuracy: 0.8170\n",
      "Epoch 42/50\n",
      "172/172 [==============================] - 45s 250ms/step - loss: 0.6427 - accuracy: 0.8180\n",
      "Epoch 43/50\n",
      "172/172 [==============================] - 45s 250ms/step - loss: 0.6420 - accuracy: 0.8182\n",
      "Epoch 44/50\n",
      "172/172 [==============================] - 46s 253ms/step - loss: 0.6413 - accuracy: 0.8176\n",
      "Epoch 45/50\n",
      "172/172 [==============================] - 46s 251ms/step - loss: 0.6427 - accuracy: 0.8176\n",
      "Epoch 46/50\n",
      "172/172 [==============================] - 45s 249ms/step - loss: 0.6405 - accuracy: 0.8179\n",
      "Epoch 47/50\n",
      "172/172 [==============================] - 45s 251ms/step - loss: 0.6418 - accuracy: 0.8175\n",
      "Epoch 48/50\n",
      "172/172 [==============================] - 45s 250ms/step - loss: 0.6403 - accuracy: 0.8179\n",
      "Epoch 49/50\n",
      "172/172 [==============================] - 45s 250ms/step - loss: 0.6394 - accuracy: 0.8176\n",
      "Epoch 50/50\n",
      "172/172 [==============================] - 46s 250ms/step - loss: 0.6429 - accuracy: 0.8163\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset, epochs=50, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We have now trained our model - great! Let us check it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: \n",
      " \"MNIA:\\nO, he is wounded; I thank the gods for't.\\n\\nMENENIUS:\\nSo do I too, if it be not too much: bring\"\n",
      "\n",
      "Next Char Predictions: \n",
      " \"OOE:\\nO, se is nounded? I'ehank theeaaws forgt:\\n\\nEENENIUS:\\nIi iooI to;, if it be non\\nto ,such,\\nbuidgs\"\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "sampled_indices = tf.random.categorical(tf.math.log(example_batch_predictions)[0], \n",
    "                                        num_samples=1)\n",
    "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()\n",
    "\n",
    "# Still not good! \n",
    "print(\"Input: \\n\", repr(\"\".join(idx2char[input_example_batch[0]])))\n",
    "print()\n",
    "print(\"Next Char Predictions: \\n\", repr(\"\".join(idx2char[sampled_indices ])))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## How to predict more than one character?\n",
    "\n",
    "Our network only predicts ONE character at a time - but we want to generate long sequences of text!\n",
    "\n",
    "This is easily handled by simply *using each prediction as input to the next prediction*.\n",
    "\n",
    "<img src=\"./graphics/text_generation_sampling.png\" alt=\"Drawing\" style=\"width: 800px;\"/>\n",
    "Source: https://www.tensorflow.org/tutorials/text/text_generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "To keep the prediction step simple, use a batch size of 1.\n",
    "\n",
    "Because of the way the RNN state is passed from timestep to timestep, \n",
    "the model only accepts a fixed batch size once built.\n",
    "\n",
    "To run the model with a different batch_size, w\n",
    "e need to rebuild the model and restore the weights from the checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_10 (Embedding)    (1, None, 256)            16640     \n",
      "                                                                 \n",
      " gru_13 (GRU)                (1, None, 1024)           3938304   \n",
      "                                                                 \n",
      " dense_10 (Dense)            (1, None, 65)             66625     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,021,569\n",
      "Trainable params: 4,021,569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "\n",
    "model.build(tf.TensorShape([1, None]))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We need to format the text (i.e. the predictions) to look pretty to us \"humans\".\n",
    "\n",
    "The function on the next page makes it more pretty to look at for us.\n",
    "\n",
    "Further, it provides some options on how to make the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def generate_text(model, start_string, num_generate = 300, sample = True, \n",
    "                  stateless = False,visuals = False):\n",
    "    # Converting our start string to numbers (vectorizing)\n",
    "    input_eval = [char2idx[s] for s in start_string]\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "    # Empty string to store our results\n",
    "    text_generated = []\n",
    "\n",
    "    model.reset_states()\n",
    "    for i in range(num_generate):\n",
    "        if visuals:\n",
    "            print(f'input_eval {i}: {input_eval.shape}')\n",
    "        \n",
    "        predictions = model(input_eval)\n",
    "        \n",
    "        if visuals:\n",
    "            print(f'sequence {i}: {predictions.shape}')\n",
    "\n",
    "        predictions = tf.squeeze(predictions, 0) # remove the batch dimension\n",
    "        \n",
    "        if sample:\n",
    "            predicted_id = tf.random.categorical(tf.math.log(predictions), \n",
    "                                                 num_samples=1)[-1,0].numpy()\n",
    "        else:\n",
    "            predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "\n",
    "        # We pass the predicted character as the next input to the model\n",
    "        # along with the previous hidden state\n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "        \n",
    "        text_generated.append(idx2char[predicted_id])\n",
    "        if visuals:\n",
    "            print(f'text: {\"\".join(text_generated)}')\n",
    "        \n",
    "        # if stateless, we DO NOT pass along hidden state. This is a terrible idea\n",
    "        if stateless:\n",
    "            model.reset_states()\n",
    "\n",
    "    return start_string + ''.join(text_generated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "And now, with the model and a way to format the data, there is only one thing to do...\n",
    "\n",
    "Let us see what I have to say - according the the network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_eval 0: (1, 10)\n",
      "sequence 0: (1, 10, 65)\n",
      "text: y\n",
      "input_eval 1: (1, 1)\n",
      "sequence 1: (1, 1, 65)\n",
      "text: yo\n",
      "input_eval 2: (1, 1)\n",
      "sequence 2: (1, 1, 65)\n",
      "text: you\n",
      "input_eval 3: (1, 1)\n",
      "sequence 3: (1, 1, 65)\n",
      "text: you \n",
      "input_eval 4: (1, 1)\n",
      "sequence 4: (1, 1, 65)\n",
      "text: you m\n",
      "input_eval 5: (1, 1)\n",
      "sequence 5: (1, 1, 65)\n",
      "text: you mi\n",
      "input_eval 6: (1, 1)\n",
      "sequence 6: (1, 1, 65)\n",
      "text: you mis\n",
      "input_eval 7: (1, 1)\n",
      "sequence 7: (1, 1, 65)\n",
      "text: you mist\n",
      "input_eval 8: (1, 1)\n",
      "sequence 8: (1, 1, 65)\n",
      "text: you mista\n",
      "input_eval 9: (1, 1)\n",
      "sequence 9: (1, 1, 65)\n",
      "text: you mistak\n",
      "input_eval 10: (1, 1)\n",
      "sequence 10: (1, 1, 65)\n",
      "text: you mistake\n",
      "input_eval 11: (1, 1)\n",
      "sequence 11: (1, 1, 65)\n",
      "text: you mistake,\n",
      "input_eval 12: (1, 1)\n",
      "sequence 12: (1, 1, 65)\n",
      "text: you mistake,\n",
      "\n",
      "input_eval 13: (1, 1)\n",
      "sequence 13: (1, 1, 65)\n",
      "text: you mistake,\n",
      "W\n",
      "input_eval 14: (1, 1)\n",
      "sequence 14: (1, 1, 65)\n",
      "text: you mistake,\n",
      "We\n",
      "input_eval 15: (1, 1)\n",
      "sequence 15: (1, 1, 65)\n",
      "text: you mistake,\n",
      "We \n",
      "input_eval 16: (1, 1)\n",
      "sequence 16: (1, 1, 65)\n",
      "text: you mistake,\n",
      "We s\n",
      "input_eval 17: (1, 1)\n",
      "sequence 17: (1, 1, 65)\n",
      "text: you mistake,\n",
      "We se\n",
      "input_eval 18: (1, 1)\n",
      "sequence 18: (1, 1, 65)\n",
      "text: you mistake,\n",
      "We set\n",
      "input_eval 19: (1, 1)\n",
      "sequence 19: (1, 1, 65)\n",
      "text: you mistake,\n",
      "We set \n",
      "input_eval 20: (1, 1)\n",
      "sequence 20: (1, 1, 65)\n",
      "text: you mistake,\n",
      "We set t\n",
      "input_eval 21: (1, 1)\n",
      "sequence 21: (1, 1, 65)\n",
      "text: you mistake,\n",
      "We set th\n",
      "input_eval 22: (1, 1)\n",
      "sequence 22: (1, 1, 65)\n",
      "text: you mistake,\n",
      "We set the\n",
      "input_eval 23: (1, 1)\n",
      "sequence 23: (1, 1, 65)\n",
      "text: you mistake,\n",
      "We set the \n",
      "input_eval 24: (1, 1)\n",
      "sequence 24: (1, 1, 65)\n",
      "text: you mistake,\n",
      "We set the a\n",
      "input_eval 25: (1, 1)\n",
      "sequence 25: (1, 1, 65)\n",
      "text: you mistake,\n",
      "We set the ax\n",
      "input_eval 26: (1, 1)\n",
      "sequence 26: (1, 1, 65)\n",
      "text: you mistake,\n",
      "We set the axe\n",
      "input_eval 27: (1, 1)\n",
      "sequence 27: (1, 1, 65)\n",
      "text: you mistake,\n",
      "We set the axe \n",
      "input_eval 28: (1, 1)\n",
      "sequence 28: (1, 1, 65)\n",
      "text: you mistake,\n",
      "We set the axe t\n",
      "input_eval 29: (1, 1)\n",
      "sequence 29: (1, 1, 65)\n",
      "text: you mistake,\n",
      "We set the axe to\n",
      "LECTURER: you mistake,\n",
      "We set the axe to\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, start_string=\"LECTURER: \", num_generate=30,visuals=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE STUDENT: she is well.\n",
      "How is't your mistress\n",
      "We follow'd to-morrow no incense, yet they\n",
      "Upon this is the rabbect, standing each part\n",
      "The heavy lion-fiends still live che to them.\n",
      "\n",
      "COMINIUS:\n",
      "I know ye well.\n",
      "\n",
      "ANGELO:\n",
      "Were you in your suit!\n",
      "\n",
      "Apacrion, obe in all duty, freed the better, time an arguill\n",
      "To my det\n"
     ]
    }
   ],
   "source": [
    "# Or what about you?\n",
    "print(generate_text(model, start_string=\"THE STUDENT: \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE RESPONSIBLE: has best believe the\n",
      "purposes in the field?\n",
      "I think, say I would say 'twere past all brought together, must\n",
      "In open rance, as I though my reasons are\n",
      "cure-diercus for that sounds:\n",
      "I God, Hermione would the work about the government of Clarence,\n",
      "That private him sings? called me but every tood,\n",
      "That \n"
     ]
    }
   ],
   "source": [
    "# Or what about Christian M. Dahl..the course responsible\n",
    "print(generate_text(model, start_string=\"THE RESPONSIBLE: \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Christian: faith becomes thy foolish knavest in your stomach, though make pale?\n",
      "\n",
      "CLIFFORD:\n",
      "Plantagenet! for he gives my sweet wonder and\n",
      "call me to bey the like ancertier.\n",
      "\n",
      "PETRUCHIO:\n",
      "And you.\n",
      "\n",
      "CORIOLANUS:\n",
      "Voul-placery and gone.\n",
      "\n",
      "SEBASTIAN:\n",
      "Good with an unloverch for my boss:\n",
      "Might have found inclination: he h\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, start_string=\"Christian: \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The importance of sampling\n",
    "\n",
    "A problem with not using sampling (aside from it not being very \"creative\") is that it **potentially** results in looping.\n",
    "\n",
    "This specific example looks fine, but I promise that there are many catastrophic cases (\"my\" network just happened to behave well).\n",
    "\n",
    "<img src=\"./graphics/IllustratingSampling.PNG\" alt=\"Drawing\" style=\"width: 800px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE STUDENTIO:\n",
      "And when the king shall be common fools; if you had\n",
      "When such a fellow is a gentle provost:\n",
      "The other for us in a pick, if thou hast\n",
      "The ordering of the mind of Bolingbroke\n",
      "It for the son of Henry the Fourth!\n",
      "\n",
      "KING EDWARD IV:\n",
      "But now you have made fair work, some dear dog! shall I be so contente\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, start_string=\"THE STUDENT\", num_generate=300, \n",
    "                    sample=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Importance of state\n",
    "\n",
    "Without the hidden state, the model goes crazy. This is not surprising, as it is not enough only to know the last letter to write something meaningful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE LECTURER: MINDUCKINCKINUCKIOLANUCKIO:\n",
      "RDYOMOLOFFFRDULANDWhe,\n",
      "Whevizen wan,\n",
      "TENCHARIDULINTIOPELINCKINTHOLANICK:\n",
      "Whe METRKINCKETERK:\n",
      "T:\n",
      "TINUCKILABY:\n",
      "Whamend he,\n",
      "TINCUCKIOLUCHOPENCKINCK:\n",
      "TADUCKINULOFRIUST:\n",
      "BY:\n",
      "ANINTERK:\n",
      "CK:\n",
      "ANCKINTHANINCKI ISTIOMINCKIOLANUCUCK:\n",
      "TETHOPENDWhevend;\n",
      "OMIOFRKINULOFFOWhe,\n",
      "CKINUCKININES\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, start_string=\"THE LECTURER: \", num_generate=300, \n",
    "                    stateless=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## No sampling, no state, no fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE LECTURER: INCKINCKINCKINCKINCKINCKINCKINCKINCKINCKINCKINCKINCKINCKINCKINCKINCKINCKINCKINCKINCKINCKINCKINCKINCKINCKINCKINCKINCKINCKINCKINCKINCKINCKINCKINCKINCKINCKINCKINCKINCKINCKINCKINCKINCKINCKINCKINCKINCKINCKINCKINCKINCKINCKINCKINCKINCKINCKINCKINCKINCKINCKINCKINCKINCKINCKINCKINCKINCKINCKINCKINCKINCKINCKINCK\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, start_string=\"THE LECTURER: \", num_generate=300, \n",
    "                    sample=False, stateless=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## How to improve the model\n",
    "\n",
    "The model presented in these slides is decent but not super impressive. However, it is also very simple (and since we perform character prediction, the model needs to spell/use grammer and so on!). You may want to try to improve it.\n",
    "\n",
    "Specifically, you may want to:\n",
    "1. Use a larger model. Embedding, nodes in GRU, even potentially more layers.\n",
    "2. Train for more epochs.\n",
    "3. Apply different optimization and/or regularization.\n",
    "4. Use a different architecture.\n",
    "5. Use words instead of characters.\n",
    "\n",
    "In general, tinkering with a model to try to improve performance is a great way to become more familiar with a topic - so try to see how much you can improve it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Classical language models\n",
    "\n",
    "An important method in natural language processing (NLP) - as well as other topics - is the concept of *attention*. This has laid the foundation of transformer networks (*this is something else than a spatial transformer!*).\n",
    "\n",
    "For those of you interested in learning more, I suggest you may read more on this. One approach would be to:\n",
    "1. Read \"Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., ... & Polosukhin, I. (2017). Attention is all you need. In Advances in neural information processing systems (pp. 5998-6008)\", see https://arxiv.org/abs/1706.03762. Paper that introduces the transformer.\n",
    "1. Then read \"Brown, T. B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P., ... & Agarwal, S. (2020). Language models are few-shot learners. arXiv preprint arXiv:2005.14165\", see https://arxiv.org/abs/2005.14165. Some of the amazing results by scaling models up BIG (175B parameters)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Some suggestions for further work\n",
    "\n",
    "The generative example we worked with today was built directly on raw text. This means that it can work quite easily on other sources of text data.\n",
    "\n",
    "As such, if you want to explore more, I suggest you find some text data you find fun. This may be a text conversation you have with someone else - maybe a group conversation - a piece of literature you like, or something else.\n",
    "\n",
    "Then, try to apply the same techniques (most of the code does not need to change). Perhaps you can come up with something fun!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Advantages and disadvantages of RNNs\n",
    "\n",
    "Advantages\n",
    "1. RNNs are a type of model that allows the learning of long-term dependencies by making efficient use of parameter sharing.\n",
    "1. Although not directly related to RNNs, embedding layers are a powerful tool to map sparse data (such as one-hot encoded words) to dense matrices. Combining embedding layers with RNNs allows for powerful language models.\n",
    "1. RNNs may be used to perform sequence prediction, including using them in an \"autoregressive\" way (using their output as a new input), which allows for generative modelling.\n",
    "\n",
    "Disadvantages\n",
    "1. RNNs are notoriously difficult and slow to train, since the loop has to be unfolded for backpropagation. This results in extremely deep models for long sequences.\n",
    "1. This had led to research in e.g. NLP to focus on non-RNN models, such as the transformer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summary and looking ahead\n",
    "\n",
    "In these lecture, we dived deep into the world of NLP and more generally working with sequential data, covering in detail RNNs, including their structure and use, what tricks they use to manage sequential data, and getting a brief glimpse at what the current SOTA looks like.\n",
    "\n",
    "Further, we encountered for the first time generative modelling. \n",
    "\n",
    "As such, this lecture is a turning point. Moving forward, we will dive beyond the topics covered in *Deep Learning*, moving on to highly advanced generative modelling. We will start by learning about (variational) autoencoders and then move on to generative adversarial networks.\n",
    "\n",
    "Much of the work done in these fields deal with CNNs, but the methods are much more general. That is, even though we will work extensively with image data rest assured that the methods are useful in many fields."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
