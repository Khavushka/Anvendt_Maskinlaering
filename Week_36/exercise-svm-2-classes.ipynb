{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise - SVM for classification of 2 classes\n",
    "\n",
    "1. Replicate the example from the slides, but using the $\\texttt{make_moons}$ instead of the $\\texttt{make_circles}$ dataset. That is, replace $\\texttt{from sklearn.datasets import make_circles}$ with $\\texttt{from sklearn.datasets import make_moons}$ and use this new function to generate $\\texttt{X}$ and $\\texttt{y}$. Then, check how the linear, polynomial, and radial basis function performs on this new dataset (by calculating and reporting their test accuracies).\n",
    "1. The default setting for $C$, the regularization parameter, is $1$. Try to adjust this (both up and down) and see how the performance of your models changes.\n",
    "1. Try to split your training data (again using $\\texttt{train_test_split}$) to obtain a validation set. Try to tune your **polynomial** SVM (by changing the degree of the kernel and C) to obtain the best model on your validation data. Apply this model to your test data. Did you improve your model's performance on the test data?\n",
    "\n",
    "**See slides for more details!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1\n",
    "\n",
    "Replicate the example from the slides, but using the $\\texttt{make_moons}$ instead of the $\\texttt{make_circles}$ dataset. That is, replace $\\texttt{from sklearn.datasets import make_circles}$ with $\\texttt{from sklearn.datasets import make_moons}$ and use this new function to generate $\\texttt{X}$ and $\\texttt{y}$. Then, check how the linear, polynomial, and radial basis function performs on this new dataset (by calculating and reporting their test accuracies)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2292128633.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\cmd\\AppData\\Local\\Temp\\1\\ipykernel_40456\\2292128633.py\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    from sklearn.datasets import  # import the make_moons dataset!\u001b[0m\n\u001b[1;37m                                  ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import  # import the make_moons dataset!\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import svm\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Use the `make_moons` function to construct your dataset\n",
    "X, y = make_moons(n_samples=1000, noise=0.05, random_state=42)\n",
    "\n",
    "# Use `train_test_split` to split your data into a train and a test set.\n",
    "X_train, X_test, y_train, y_test = \n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "# Let us look at the data\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.get_cmap(\"winter_r\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a linear SVM\n",
    "svm_linear = \n",
    "\n",
    "# Fit your SVM\n",
    "svm_linear.fit\n",
    "\n",
    "# Predict on your test data with your linear SVM\n",
    "y_test_hat_linear = svm_linear.predict\n",
    "\n",
    "# Obtain accuracy by using the `accuracy_score` function\n",
    "accuracy_linear = \n",
    "\n",
    "# Print results\n",
    "print(f'Linear SVM achieved {round(accuracy_linear * 100, 1)}% accuracy.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a polynomial SVM of degree 2\n",
    "svm_poly = \n",
    "\n",
    "# Fit your SVM\n",
    "svm_poly\n",
    "\n",
    "# Predict on your test data with your linear SVM\n",
    "y_test_hat_svm_poly =\n",
    "\n",
    "# Obtain accuracy by using the `accuracy_score` function\n",
    "accuracy_linear = \n",
    "\n",
    "# Print results\n",
    "print(f'Polynomial SVM achieved XXX% accuracy.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the same for the radial basis function kernel!\n",
    "# Remember to look at the example for hints\n",
    "\n",
    "type the code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize your results (you do not need to change anything in this block)\n",
    "fig = plt.figure(figsize=plt.figaspect(0.2))\n",
    "ax = fig.add_subplot(1, 4, 1)\n",
    "ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=plt.get_cmap(\"winter_r\"))\n",
    "plt.title('Truth')\n",
    "\n",
    "ax = fig.add_subplot(1, 4, 2)\n",
    "ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test_hat_linear, cmap=plt.get_cmap(\"winter_r\"))\n",
    "plt.title('Linear SVM')\n",
    "\n",
    "ax = fig.add_subplot(1, 4, 3)\n",
    "ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test_hat_poly, cmap=plt.get_cmap(\"winter_r\"))\n",
    "plt.title('Quadratic SVM')\n",
    "\n",
    "ax = fig.add_subplot(1, 4, 4)\n",
    "ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test_hat_rbf, cmap=plt.get_cmap(\"winter_r\"))\n",
    "plt.title('RBF SVM')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2\n",
    "\n",
    "The default setting for $C$, the regularization parameter, is $1$. Try to adjust this (both up and down) and see how the performance of your models changes.\n",
    "\n",
    "I suggest using $0.01$ for the low value and $100$ for the high value, but you decide.\n",
    "\n",
    "Perhaps do it just for the polynomial and the RBF kernels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do it for a polynomial kernel of whatever degree you want (but SAME for both!)\n",
    "\n",
    "# Initialize 2 polynomial SVMs, one with low and one with high C\n",
    "svm_poly_low_C = svm.SVC(kernel='poly', degree=??, C=0.01)\n",
    "svm_poly_high_C = svm.SVC(kernel='poly', degree=??, C=100)\n",
    "\n",
    "# Fit your SVMs\n",
    "svm_poly_low_C.fit()\n",
    "svm_poly_high_C\n",
    "\n",
    "# Predict on your test data with your polynomial SVMs\n",
    "y_test_hat_poly_low_C = svm_poly_low_C.predict\n",
    "y_test_hat_poly_high_C = \n",
    "\n",
    "# Obtain accuracies of your linear SVMs by using the `accuracy_score` function\n",
    "accuracy_poly_low_C = accuracy_score(y_test_hat_poly_low_C, y_test)\n",
    "accuracy_poly_high_C = \n",
    "\n",
    "# Print results\n",
    "print(f'Polynomial SVM with low C achieved {round(accuracy_poly_low_C * 100, 1)}% accuracy.')\n",
    "print(f'Polynomial SVM with high C achieved {round(accuracy_poly_high_C * 100, 1)}% accuracy.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next you should do it for a RBF kernel\n",
    "\n",
    "# Initialize 2 polynomial RBF, one with low and one with high C\n",
    "svm_rbf_low_C = svm.SVC(kernel='rbf', C=0.01)\n",
    "svm_rbf_high_C = svm.SVC(kernel='rbf', C=100)\n",
    "\n",
    "# Fit your SVMs\n",
    "svm_rbf_low_C\n",
    "svm_rbf_high_C\n",
    "\n",
    "# Predict on your test data with your polynomial SVMs\n",
    "y_test_hat_rbf_low_C = \n",
    "y_test_hat_rbf_high_C = \n",
    "\n",
    "# Obtain accuracies of your linear SVMs by using the `accuracy_score` function\n",
    "accuracy_rbf_low_C = \n",
    "accuracy_rbf_high_C = \n",
    "\n",
    "# Print results\n",
    "print(f'RBF SVM with low C achieved {round(accuracy_rbf_low_C * 100, 1)}% accuracy.')\n",
    "print(f'RBF SVM with high C achieved {round(accuracy_rbf_high_C * 100, 1)}% accuracy.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize your results (you do not need to change anything in this block!)\n",
    "fig = plt.figure(figsize=plt.figaspect(0.2))\n",
    "ax = fig.add_subplot(1, 5, 1)\n",
    "ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=plt.get_cmap(\"winter_r\"))\n",
    "plt.title('Truth')\n",
    "\n",
    "ax = fig.add_subplot(1, 5, 2)\n",
    "ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test_hat_poly_low_C, cmap=plt.get_cmap(\"winter_r\"))\n",
    "plt.title('Poly low C')\n",
    "\n",
    "ax = fig.add_subplot(1, 5, 3)\n",
    "ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test_hat_poly_high_C, cmap=plt.get_cmap(\"winter_r\"))\n",
    "plt.title('Poly high C')\n",
    "\n",
    "ax = fig.add_subplot(1, 5, 4)\n",
    "ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test_hat_rbf_low_C, cmap=plt.get_cmap(\"winter_r\"))\n",
    "plt.title('RBF low C')\n",
    "\n",
    "ax = fig.add_subplot(1, 5, 5)\n",
    "ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test_hat_rbf_high_C, cmap=plt.get_cmap(\"winter_r\"))\n",
    "plt.title('RBF high C')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3\n",
    "\n",
    "Try to split your training data (again using $\\texttt{train_test_split}$) to obtain a validation set. Try to tune your **polynomial** SVM (by changing the degree of the kernel and C) to obtain the best model on your validation data. Apply this model to your test data. Did you improve your model's performance on the test data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start by splitting training data into train and a validation data\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "print(X_train.shape, X_val.shape, X_test.shape, y_train.shape, y_val.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to use different degrees and Cs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "poly_degrees = [] # input values seperated by \",\".\n",
    "Cs = [] # input values seperated by \",\".\n",
    "\n",
    "results = []\n",
    "\n",
    "for degree in poly_degrees:\n",
    "    for C in Cs:\n",
    "        svm_poly = svm.SVC(kernel='poly', degree=degree, C=C)\n",
    "        svm_poly.fit(X_train, y_train)\n",
    "        y_val_hat = svm_poly.predict(X_val)\n",
    "        accuracy = accuracy_score(y_val_hat, y_val)\n",
    "        \n",
    "        results.append([accuracy, degree, C])\n",
    "\n",
    "results = pd.DataFrame(results)\n",
    "results.columns = ['Accuracy', 'Polynomial degree', 'C']\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract best parameters.\n",
    "results[results['Accuracy'] == results['Accuracy'].max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize your final model\n",
    "svm_poly_best = svm.SVC(kernel='poly', degree=5, C = 1000)\n",
    "\n",
    "# Use both training and validation data to fit it (np.concatenate \"stacks\" the array like rbind in R)\n",
    "svm_poly_best.fit(np.concatenate([X_train, X_val]), np.concatenate([y_train, y_val]))\n",
    "\n",
    "# Predict on test data\n",
    "y_val_hat_poly_best = \n",
    "\n",
    "# Obtain and check accuracy on test data\n",
    "accuracy_poly_best = \n",
    "print(f'Optimized polynomial SVM achieved {round(accuracy_poly_best * 100, 1)}% accuracy.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize your results (you do not need to change anything in this block)\n",
    "fig = plt.figure(figsize=plt.figaspect(0.4))\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=plt.get_cmap(\"winter_r\"))\n",
    "plt.title('Truth')\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "ax.scatter(X_test[:, 0], X_test[:, 1], c=y_val_hat_poly_best, cmap=plt.get_cmap(\"winter_r\"))\n",
    "plt.title('Optimized polynomial SVM')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
