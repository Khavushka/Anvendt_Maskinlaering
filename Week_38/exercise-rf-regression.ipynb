{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise - RFs for regression\n",
    "\n",
    "1. Use the **fetch_california_housing** data (remember to split your data into a train, validation, and test data). Using your training and validation data, optimize the parameters of your RF. How well does your optimized model perform on the test data?\n",
    "   \n",
    "**Note**: This dataset is **much** larger than what we have otherwise been using. This means you cannot try a million different things without the code running very slowly!\n",
    "\n",
    "**See slides for more details!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13209, 8) (3303, 8) (4128, 8) (13209,) (3303,) (4128,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import ensemble\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.datasets import clear_data_home\n",
    "clear_data_home() #Clears the data cache\n",
    "\n",
    "X, y = fetch_california_housing(return_X_y=True, as_frame=True)\n",
    "\n",
    "# Use `train_test_split` to split your data into a train and a test set.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Use `train_test_split` to split your train data into a train and a validation  set.\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "print(X_train.shape, X_val.shape, X_test.shape, y_train.shape, y_val.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1\n",
    "\n",
    "Use the **fetch_california_housing** data (remember to split your data into a train, validation, and test data). Using your training and validation data, optimize the parameters of your RF. How well does your optimized model perform on the test data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us start by ensuring we can just run an RF without any optimization. Note how it is slower than a lot of what we have done so far!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF with default settings has validation MSE of 0.2743774459881363.\n"
     ]
    }
   ],
   "source": [
    "rf_current = ensemble.RandomForestRegressor()\n",
    "rf_current.fit(X_train, y_train)\n",
    "y_val_hat = rf_current.predict(X_val)\n",
    "mse = mean_squared_error(y_val, y_val_hat)\n",
    "\n",
    "print(f'RF with default settings has validation MSE of {mse}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        MSE  n_estimators  min_samples_split  min_samples_leaf\n",
      "0  0.321157             5                  5                 5\n",
      "1  0.335326             5                  5                10\n",
      "2  0.330966             5                 10                 5\n",
      "3  0.331609             5                 10                10\n",
      "4  0.302980            10                  5                 5\n",
      "5  0.303593            10                  5                10\n",
      "6  0.295841            10                 10                 5\n",
      "7  0.307761            10                 10                10\n"
     ]
    }
   ],
   "source": [
    "# Remember you can try other stuff than these specific parameters.\n",
    "# Just here to get you started!\n",
    "\n",
    "n_estimators_list = [5,10]  # Add more values to explore\n",
    "min_samples_split_list = [5, 10]  # Add more values to explore\n",
    "min_samples_leaf_list = [5, 10] \n",
    "\n",
    "results = []\n",
    "\n",
    "for n_estimators in n_estimators_list:\n",
    "    for min_samples_split in min_samples_split_list:\n",
    "        for min_samples_leaf in min_samples_leaf_list:\n",
    "            rf_current = ensemble.RandomForestRegressor(\n",
    "                n_estimators=n_estimators,\n",
    "                min_samples_split=min_samples_split,\n",
    "                min_samples_leaf=min_samples_leaf,\n",
    "                )\n",
    "            rf_current.fit(X_train, y_train)\n",
    "            y_val_hat = rf_current.predict(X_val)\n",
    "            mse = mean_squared_error(y_val, y_val_hat)\n",
    "\n",
    "            results.append([mse, n_estimators, min_samples_split, min_samples_leaf])\n",
    "\n",
    "results = pd.DataFrame(results)\n",
    "results.columns = ['MSE', 'n_estimators', 'min_samples_split', 'min_samples_leaf']\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.335326</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        MSE  n_estimators  min_samples_split  min_samples_leaf\n",
       "1  0.335326             5                  5                10"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract best parameters.\n",
    "results[results['MSE'] == results['MSE'].max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13209, 8) (3303, 8) (13209,) (3303,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_val.shape, y_train.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: continuous. Maybe you are trying to fit a classifier, which expects discrete classes on a regression target with continuous values.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\khavu\\Desktop\\DataScience\\3 semester\\Anvendt Maskinl√¶ring\\Week_38\\exercise-rf-regression.ipynb Cell 9\u001b[0m line \u001b[0;36m8\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/khavu/Desktop/DataScience/3%20semester/Anvendt%20Maskinl%C3%A6ring/Week_38/exercise-rf-regression.ipynb#X11sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m X_train_val \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate((X_train, X_val))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/khavu/Desktop/DataScience/3%20semester/Anvendt%20Maskinl%C3%A6ring/Week_38/exercise-rf-regression.ipynb#X11sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m y_train_val \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate((y_train, y_val))\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/khavu/Desktop/DataScience/3%20semester/Anvendt%20Maskinl%C3%A6ring/Week_38/exercise-rf-regression.ipynb#X11sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m final_rf\u001b[39m.\u001b[39;49mfit(X_train_val, y_train_val)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/khavu/Desktop/DataScience/3%20semester/Anvendt%20Maskinl%C3%A6ring/Week_38/exercise-rf-regression.ipynb#X11sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# Step 5: Evaluate the final model on the test data\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/khavu/Desktop/DataScience/3%20semester/Anvendt%20Maskinl%C3%A6ring/Week_38/exercise-rf-regression.ipynb#X11sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m y_test_hat \u001b[39m=\u001b[39m final_rf\u001b[39m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\tree\\_classes.py:959\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    928\u001b[0m \u001b[39m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    929\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m    930\u001b[0m     \u001b[39m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[0;32m    931\u001b[0m \n\u001b[0;32m    932\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    956\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m    957\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 959\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m_fit(\n\u001b[0;32m    960\u001b[0m         X,\n\u001b[0;32m    961\u001b[0m         y,\n\u001b[0;32m    962\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m    963\u001b[0m         check_input\u001b[39m=\u001b[39;49mcheck_input,\n\u001b[0;32m    964\u001b[0m     )\n\u001b[0;32m    965\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\tree\\_classes.py:284\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    281\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n\u001b[0;32m    283\u001b[0m \u001b[39mif\u001b[39;00m is_classification:\n\u001b[1;32m--> 284\u001b[0m     check_classification_targets(y)\n\u001b[0;32m    285\u001b[0m     y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mcopy(y)\n\u001b[0;32m    287\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_ \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\utils\\multiclass.py:216\u001b[0m, in \u001b[0;36mcheck_classification_targets\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    208\u001b[0m y_type \u001b[39m=\u001b[39m type_of_target(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    209\u001b[0m \u001b[39mif\u001b[39;00m y_type \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m [\n\u001b[0;32m    210\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    211\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mmultilabel-sequences\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    215\u001b[0m ]:\n\u001b[1;32m--> 216\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    217\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnknown label type: \u001b[39m\u001b[39m{\u001b[39;00my_type\u001b[39m}\u001b[39;00m\u001b[39m. Maybe you are trying to fit a \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    218\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mclassifier, which expects discrete classes on a \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    219\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mregression target with continuous values.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    220\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown label type: continuous. Maybe you are trying to fit a classifier, which expects discrete classes on a regression target with continuous values."
     ]
    }
   ],
   "source": [
    "final_rf = tree.DecisionTreeClassifier(\n",
    "    min_samples_split=10,\n",
    "    min_samples_leaf=5,\n",
    "    max_features=10,\n",
    "    )\n",
    "\n",
    "X_train_val = np.concatenate((X_train, X_val))\n",
    "y_train_val = np.concatenate((y_train, y_val))\n",
    "final_rf.fit(X_train_val, y_train_val)\n",
    "\n",
    "y_test_hat = final_rf.predict(X_test)\n",
    "mse_test = mean_squared_error(y_test, y_test_hat)\n",
    "print(f'Final RF model with optimized hyperparameters has test MSE of {mse_test}.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
