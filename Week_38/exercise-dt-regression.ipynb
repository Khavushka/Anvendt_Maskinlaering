{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise - DTs for regression\n",
    "\n",
    "1. Use the `./data/HousingData.csv` data (remember to split your data into a train and test data). Using your training and validation data, optimize the parameters of your DT. How well does your optimized model perform on the test data?\n",
    "1. (Optional/bonus): Try to perform standardization to your data. Does it improve your model? Further, try to select only the 5 most important features. Does it improve the performance of your model?\n",
    "\n",
    "**See slides for more details!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD  TAX  PTRATIO  \\\n",
      "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900    1  296     15.3   \n",
      "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671    2  242     17.8   \n",
      "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671    2  242     17.8   \n",
      "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622    3  222     18.7   \n",
      "5  0.02985   0.0   2.18   0.0  0.458  6.430  58.7  6.0622    3  222     18.7   \n",
      "\n",
      "        B  LSTAT  MEDV  \n",
      "0  396.90   4.98  24.0  \n",
      "1  396.90   9.14  21.6  \n",
      "2  392.83   4.03  34.7  \n",
      "3  394.63   2.94  33.4  \n",
      "5  394.12   5.21  28.7  \n",
      "\n",
      "The shape of train, validation and test sets are:\n",
      "(252, 13) (63, 13) (79, 13) (252,) (63,) (79,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import tree\n",
    "\n",
    "data = './data/HousingData.csv'\n",
    "raw_df = pd.read_csv(data).dropna()\n",
    "\n",
    "print(raw_df.head())\n",
    "\n",
    "# Create a copy of the DataFrame with column names\n",
    "df_copy = raw_df.copy()\n",
    "\n",
    "# Separate the target variable (y) and features (X)\n",
    "y = df_copy['MEDV']  # Replace 'TargetColumn' with your actual target column name\n",
    "\n",
    "# MEDV - median value of owner occupied\n",
    "X = df_copy.drop(columns=['MEDV'])  # Remove the target column\n",
    "\n",
    "# Use `train_test_split` to split your data into a train and a test set.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Use `train_test_split` to split your train data into a train and a validation  set.\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"\\nThe shape of train, validation and test sets are:\")\n",
    "print(X_train.shape, X_val.shape, X_test.shape, y_train.shape, y_val.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1\n",
    "\n",
    "Use the `./data/HousingData.csv` data (remember to split your data into a train and test data). Using your training and validation data, optimize the parameters of your DT. How well does your optimized model perform on the test data? Is it better than your optimized SVM for the same data (the third exercise from last week)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          MSE  min_samples_split  min_samples_leaf  max_features\n",
      "0   11.474091                  2                 5             2\n",
      "1   18.755583                  2                 5             5\n",
      "2   28.926581                  2                 5            10\n",
      "3   22.719969                  2                10             2\n",
      "4   28.074906                  2                10             5\n",
      "5   13.557582                  2                10            10\n",
      "6   22.514651                  2                15             2\n",
      "7   15.911417                  2                15             5\n",
      "8   15.197658                  2                15            10\n",
      "9   36.234507                  4                 5             2\n",
      "10  15.905257                  4                 5             5\n",
      "11  23.447054                  4                 5            10\n",
      "12  26.912885                  4                10             2\n",
      "13  20.320952                  4                10             5\n",
      "14  25.276486                  4                10            10\n",
      "15  32.592028                  4                15             2\n",
      "16  23.812991                  4                15             5\n",
      "17  18.224983                  4                15            10\n",
      "18  26.483770                  6                 5             2\n",
      "19  11.858365                  6                 5             5\n",
      "20  24.865873                  6                 5            10\n",
      "21  28.064720                  6                10             2\n",
      "22  21.488006                  6                10             5\n",
      "23  19.617108                  6                10            10\n",
      "24  34.284566                  6                15             2\n",
      "25  33.889916                  6                15             5\n",
      "26  15.904925                  6                15            10\n",
      "27  18.106041                 12                 5             2\n",
      "28  25.793042                 12                 5             5\n",
      "29  24.300190                 12                 5            10\n",
      "30  21.212241                 12                10             2\n",
      "31  31.474811                 12                10             5\n",
      "32  21.891377                 12                10            10\n",
      "33  42.748998                 12                15             2\n",
      "34  18.372666                 12                15             5\n",
      "35  21.273006                 12                15            10\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "min_samples_split_list = [2, 4, 6, 12] # input values seperated by \",\".\n",
    "min_samples_leaf_list = [5, 10, 15] # input values seperated by \",\".\n",
    "max_features_list = [2, 5, 10] # input values seperated by \",\".\n",
    "\n",
    "results = []\n",
    "\n",
    "for min_samples_split in min_samples_split_list:\n",
    "    for min_samples_leaf in min_samples_leaf_list:\n",
    "        for max_features in max_features_list:\n",
    "            dt_current = tree.DecisionTreeRegressor(min_samples_split=min_samples_split,\n",
    "                                                    min_samples_leaf=min_samples_leaf,\n",
    "                                                    max_features=max_features)\n",
    "                                                    \n",
    "            dt_current.fit(X_train, y_train)\n",
    "            y_val_hat = dt_current.predict(X_val)\n",
    "            mse = mean_squared_error(y_val, y_val_hat)\n",
    "\n",
    "            results.append([mse, min_samples_split, min_samples_leaf, max_features])\n",
    "\n",
    "results = pd.DataFrame(results)\n",
    "results.columns = ['MSE', 'min_samples_split', 'min_samples_leaf', 'max_features']\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>max_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>42.748998</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          MSE  min_samples_split  min_samples_leaf  max_features\n",
       "33  42.748998                 12                15             2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract best parameters.\n",
    "results[results['MSE'] == results['MSE'].max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized DT achieved MSE = 39.58. - lower values indicating better performance.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\khavu\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Initialize your final model\n",
    "dt_optimized = tree.DecisionTreeRegressor(\n",
    "    min_samples_split=10,\n",
    "    min_samples_leaf=5,\n",
    "    max_features=10,\n",
    "    )\n",
    "\n",
    "# Use both training and validation data to fit it (np.concatenate \"stacks\" the array like rbind in R)\n",
    "dt_optimized.fit(np.concatenate([X_train, X_val]), np.concatenate([y_train, y_val]))\n",
    "\n",
    "# Predict on test data\n",
    "y_test_hat_optimized = dt_optimized.predict(X_test)\n",
    "\n",
    "# Obtain and check mse on test data\n",
    "mse_optimized = mean_squared_error(y_test, y_test_hat_optimized)\n",
    "print(f'Optimized DT achieved MSE = {round(mse_optimized, 2)}. - lower values indicating better performance.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2\n",
    "\n",
    "(Optional/bonus): Try to perform standardization to your data. Does it improve your model? Further, try to select only the 5 most important features. Does it improve the performance of your model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training data and transform both train and test data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dt_regressor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19712\\3981665324.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Train the decision tree regressor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdt_regressor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Get feature importances\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dt_regressor' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# Train the decision tree regressor\n",
    "dt_regressor.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get feature importances\n",
    "feature_importances = dt_regressor.feature_importances_\n",
    "\n",
    "# Create a feature selector to select the top 5 features\n",
    "selector = SelectFromModel(dt_regressor, max_features=5)\n",
    "\n",
    "# Fit the selector on your scaled training data\n",
    "X_train_selected = selector.fit_transform(X_train_scaled, y_train)\n",
    "\n",
    "# Transform your validation and test data using the same selector\n",
    "X_val_selected = selector.transform(X_val_scaled)\n",
    "X_test_selected = selector.transform(X_test_scaled)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
