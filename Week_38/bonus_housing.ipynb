{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.02985</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.430</td>\n",
       "      <td>58.7</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.12</td>\n",
       "      <td>5.21</td>\n",
       "      <td>28.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>0.17783</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.585</td>\n",
       "      <td>5.569</td>\n",
       "      <td>73.5</td>\n",
       "      <td>2.3999</td>\n",
       "      <td>6</td>\n",
       "      <td>391</td>\n",
       "      <td>19.2</td>\n",
       "      <td>395.77</td>\n",
       "      <td>15.10</td>\n",
       "      <td>17.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>0.22438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.585</td>\n",
       "      <td>6.027</td>\n",
       "      <td>79.7</td>\n",
       "      <td>2.4982</td>\n",
       "      <td>6</td>\n",
       "      <td>391</td>\n",
       "      <td>19.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>14.33</td>\n",
       "      <td>16.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>394 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD  TAX  \\\n",
       "0    0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900    1  296   \n",
       "1    0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671    2  242   \n",
       "2    0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671    2  242   \n",
       "3    0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622    3  222   \n",
       "5    0.02985   0.0   2.18   0.0  0.458  6.430  58.7  6.0622    3  222   \n",
       "..       ...   ...    ...   ...    ...    ...   ...     ...  ...  ...   \n",
       "499  0.17783   0.0   9.69   0.0  0.585  5.569  73.5  2.3999    6  391   \n",
       "500  0.22438   0.0   9.69   0.0  0.585  6.027  79.7  2.4982    6  391   \n",
       "502  0.04527   0.0  11.93   0.0  0.573  6.120  76.7  2.2875    1  273   \n",
       "503  0.06076   0.0  11.93   0.0  0.573  6.976  91.0  2.1675    1  273   \n",
       "504  0.10959   0.0  11.93   0.0  0.573  6.794  89.3  2.3889    1  273   \n",
       "\n",
       "     PTRATIO       B  LSTAT  MEDV  \n",
       "0       15.3  396.90   4.98  24.0  \n",
       "1       17.8  396.90   9.14  21.6  \n",
       "2       17.8  392.83   4.03  34.7  \n",
       "3       18.7  394.63   2.94  33.4  \n",
       "5       18.7  394.12   5.21  28.7  \n",
       "..       ...     ...    ...   ...  \n",
       "499     19.2  395.77  15.10  17.5  \n",
       "500     19.2  396.90  14.33  16.8  \n",
       "502     21.0  396.90   9.08  20.6  \n",
       "503     21.0  396.90   5.64  23.9  \n",
       "504     21.0  393.45   6.48  22.0  \n",
       "\n",
       "[394 rows x 14 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# data = pd.read_csv(r\"C:\\Users\\khavu\\Desktop\\DataScience\\3 semester\\Anvendt Maskinlæring\\HousingData.csv\")\n",
    "data = (r\"C:\\Users\\khavu\\Desktop\\DataScience\\3 semester\\Anvendt Maskinlæring\\HousingData.csv\")\n",
    "raw_data = pd.read_csv(data).dropna()\n",
    "data_copy = raw_data.copy()\n",
    "data_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(315,) (79,) (315, 13) (79, 13)\n",
      "(315,) (79,) (79,) (315, 13) (79, 13) (79, 13)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import accuracy_score\n",
    "from sklearn import ensemble\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import clear_data_home\n",
    "clear_data_home()\n",
    "\n",
    "X = data_copy['MEDV']\n",
    "y = data_copy.drop(columns=['MEDV'])\n",
    "\n",
    "# Use `train_test_split` to split your data into a train and a test set.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "# Use `train_test_split` to split your train data into a train and a validation  set.\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(X_train.shape, X_val.shape, X_test.shape, y_train.shape, y_val.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[14.2 41.7 21.5 21.4 12.8 28.6 21.8 20.1  6.3 46.  50.  25.  19.5 22.8\n 13.3 23.9 43.5 28.7 21.4 18.7 13.6 21.2 34.9 15.  14.5 15.1 13.  21.8\n 13.4 44.8 21.9  8.1 13.8 24.2 20.6 22.7 13.5 23.1 37.  19.6 19.6 12.7\n 18.4 13.1 11.8 27.5 29.  26.2 20.3 34.9 13.1 23.2 24.3 15.6 21.2 45.4\n 23.1 26.4  7.4 25.3 27.5 21.1 24.8  8.4 20.9 15.6 12.  28.1 16.5 20.8\n 17.9 20.4 30.1 18.8 21.4 35.1 36.1  7.2 20.7 10.4  7.5 19.5 19.8 37.9\n 11.7 19.8 24.8 19.6 18.8 29.9 11.3 18.7 22.  23.9 14.8 21.2 37.2 15.4\n 28.  16.1  8.3 19.6  5.6 21.2 17.  36.2 23.9 26.5 11.7 20.9  8.3 24.4\n 24.6 10.9 29.  29.6 17.8 32.2 18.2 27.  19.3 19.9 19.  31.5 16.8 18.1\n 31.6  8.4 22.2 14.4 20.1 23.1 15.2 19.9 17.7 24.4 23.1 22.3 29.1 44.\n 42.8 19.7 34.7 43.1 17.8 37.3 22.5 12.7 11.8 10.5 23.2 21.1 19.5  5.\n 13.4 24.3 23.6 17.2 13.1 43.8 10.4 14.3 13.8 20.4 25.  16.2 24.  21.9\n 18.9 19.1 20.8 13.8 27.5 21.6 23.3 22.9 32.9 23.1 26.6 13.2 23.3 23.2\n 16.7  5.  50.  22.8 16.  22.1 13.6  8.8 50.  19.4 23.2 36.5 23.   8.8\n 28.7 19.3 14.1 22.  28.5 14.3 35.2 28.7 18.5 32.  21.7 31.6 24.7 32.7\n 50.  16.1 14.5 13.1 27.1 20.7 50.  48.5 14.1 19.1 22.8 23.8 23.3 18.9\n 20.   7.2 20.2 30.3 14.4 19.1 15.  33.2 21.7  8.7 28.2 22.8 24.4 10.2\n 20.2 18.5 24.5  7.  11.5 23.9 36.  42.3 25.  29.1 24.3  8.5 22.2 16.2\n 25.  21.6 19.6 28.4 31.  34.9 18.5 20.4  9.6 22.2 20.6 19.4 17.5  8.5\n 20.1 24.5 19.3 16.7 18.3 50.   9.7 20.6 17.2 23.8 33.  18.7 21.7 17.6\n 20.6 22.2 23.7 17.4 23.3 10.8 33.4 25.  13.9 12.1 24.1 30.1 20.5 13.3\n 15.4 22.6 12.5 29.6 50.  29.8 21.4 19.2 23.7 18.6 20.8 32.4 13.8 22.\n 15.6 23.7 23.9 18.  17.5 14.1 20.5].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\khavu\\Desktop\\DataScience\\3 semester\\Anvendt Maskinlæring\\Week_38\\bonus_housing.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/khavu/Desktop/DataScience/3%20semester/Anvendt%20Maskinl%C3%A6ring/Week_38/bonus_housing.ipynb#W2sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(nb_trees):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/khavu/Desktop/DataScience/3%20semester/Anvendt%20Maskinl%C3%A6ring/Week_38/bonus_housing.ipynb#W2sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     dt \u001b[39m=\u001b[39m tree\u001b[39m.\u001b[39mDecisionTreeRegressor()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/khavu/Desktop/DataScience/3%20semester/Anvendt%20Maskinl%C3%A6ring/Week_38/bonus_housing.ipynb#W2sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     dt\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/khavu/Desktop/DataScience/3%20semester/Anvendt%20Maskinl%C3%A6ring/Week_38/bonus_housing.ipynb#W2sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     y_test_hat \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m dt\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/khavu/Desktop/DataScience/3%20semester/Anvendt%20Maskinl%C3%A6ring/Week_38/bonus_housing.ipynb#W2sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m y_test_hat \u001b[39m/\u001b[39m\u001b[39m=\u001b[39m nb_trees\n",
      "File \u001b[1;32mc:\\Users\\khavu\\anaconda3\\envs\\amlfall23\\lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\khavu\\anaconda3\\envs\\amlfall23\\lib\\site-packages\\sklearn\\tree\\_classes.py:1320\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m   1290\u001b[0m \u001b[39m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m   1291\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m   1292\u001b[0m     \u001b[39m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[0;32m   1293\u001b[0m \n\u001b[0;32m   1294\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1317\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m   1318\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1320\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m_fit(\n\u001b[0;32m   1321\u001b[0m         X,\n\u001b[0;32m   1322\u001b[0m         y,\n\u001b[0;32m   1323\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m   1324\u001b[0m         check_input\u001b[39m=\u001b[39;49mcheck_input,\n\u001b[0;32m   1325\u001b[0m     )\n\u001b[0;32m   1326\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\khavu\\anaconda3\\envs\\amlfall23\\lib\\site-packages\\sklearn\\tree\\_classes.py:242\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    238\u001b[0m check_X_params \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\n\u001b[0;32m    239\u001b[0m     dtype\u001b[39m=\u001b[39mDTYPE, accept_sparse\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcsc\u001b[39m\u001b[39m\"\u001b[39m, force_all_finite\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    240\u001b[0m )\n\u001b[0;32m    241\u001b[0m check_y_params \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(ensure_2d\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m--> 242\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m    243\u001b[0m     X, y, validate_separately\u001b[39m=\u001b[39;49m(check_X_params, check_y_params)\n\u001b[0;32m    244\u001b[0m )\n\u001b[0;32m    246\u001b[0m missing_values_in_feature_mask \u001b[39m=\u001b[39m (\n\u001b[0;32m    247\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_missing_values_in_feature_mask(X)\n\u001b[0;32m    248\u001b[0m )\n\u001b[0;32m    249\u001b[0m \u001b[39mif\u001b[39;00m issparse(X):\n",
      "File \u001b[1;32mc:\\Users\\khavu\\anaconda3\\envs\\amlfall23\\lib\\site-packages\\sklearn\\base.py:616\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    614\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mestimator\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m check_X_params:\n\u001b[0;32m    615\u001b[0m     check_X_params \u001b[39m=\u001b[39m {\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mdefault_check_params, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_X_params}\n\u001b[1;32m--> 616\u001b[0m X \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_X_params)\n\u001b[0;32m    617\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mestimator\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m check_y_params:\n\u001b[0;32m    618\u001b[0m     check_y_params \u001b[39m=\u001b[39m {\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mdefault_check_params, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params}\n",
      "File \u001b[1;32mc:\\Users\\khavu\\anaconda3\\envs\\amlfall23\\lib\\site-packages\\sklearn\\utils\\validation.py:940\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    938\u001b[0m     \u001b[39m# If input is 1D raise error\u001b[39;00m\n\u001b[0;32m    939\u001b[0m     \u001b[39mif\u001b[39;00m array\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 940\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    941\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mExpected 2D array, got 1D array instead:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39marray=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    942\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    943\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    944\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mif it contains a single sample.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[0;32m    945\u001b[0m         )\n\u001b[0;32m    947\u001b[0m \u001b[39mif\u001b[39;00m dtype_numeric \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(array\u001b[39m.\u001b[39mdtype, \u001b[39m\"\u001b[39m\u001b[39mkind\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m array\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mkind \u001b[39min\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mUSV\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    948\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    949\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdtype=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnumeric\u001b[39m\u001b[39m'\u001b[39m\u001b[39m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    950\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    951\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[14.2 41.7 21.5 21.4 12.8 28.6 21.8 20.1  6.3 46.  50.  25.  19.5 22.8\n 13.3 23.9 43.5 28.7 21.4 18.7 13.6 21.2 34.9 15.  14.5 15.1 13.  21.8\n 13.4 44.8 21.9  8.1 13.8 24.2 20.6 22.7 13.5 23.1 37.  19.6 19.6 12.7\n 18.4 13.1 11.8 27.5 29.  26.2 20.3 34.9 13.1 23.2 24.3 15.6 21.2 45.4\n 23.1 26.4  7.4 25.3 27.5 21.1 24.8  8.4 20.9 15.6 12.  28.1 16.5 20.8\n 17.9 20.4 30.1 18.8 21.4 35.1 36.1  7.2 20.7 10.4  7.5 19.5 19.8 37.9\n 11.7 19.8 24.8 19.6 18.8 29.9 11.3 18.7 22.  23.9 14.8 21.2 37.2 15.4\n 28.  16.1  8.3 19.6  5.6 21.2 17.  36.2 23.9 26.5 11.7 20.9  8.3 24.4\n 24.6 10.9 29.  29.6 17.8 32.2 18.2 27.  19.3 19.9 19.  31.5 16.8 18.1\n 31.6  8.4 22.2 14.4 20.1 23.1 15.2 19.9 17.7 24.4 23.1 22.3 29.1 44.\n 42.8 19.7 34.7 43.1 17.8 37.3 22.5 12.7 11.8 10.5 23.2 21.1 19.5  5.\n 13.4 24.3 23.6 17.2 13.1 43.8 10.4 14.3 13.8 20.4 25.  16.2 24.  21.9\n 18.9 19.1 20.8 13.8 27.5 21.6 23.3 22.9 32.9 23.1 26.6 13.2 23.3 23.2\n 16.7  5.  50.  22.8 16.  22.1 13.6  8.8 50.  19.4 23.2 36.5 23.   8.8\n 28.7 19.3 14.1 22.  28.5 14.3 35.2 28.7 18.5 32.  21.7 31.6 24.7 32.7\n 50.  16.1 14.5 13.1 27.1 20.7 50.  48.5 14.1 19.1 22.8 23.8 23.3 18.9\n 20.   7.2 20.2 30.3 14.4 19.1 15.  33.2 21.7  8.7 28.2 22.8 24.4 10.2\n 20.2 18.5 24.5  7.  11.5 23.9 36.  42.3 25.  29.1 24.3  8.5 22.2 16.2\n 25.  21.6 19.6 28.4 31.  34.9 18.5 20.4  9.6 22.2 20.6 19.4 17.5  8.5\n 20.1 24.5 19.3 16.7 18.3 50.   9.7 20.6 17.2 23.8 33.  18.7 21.7 17.6\n 20.6 22.2 23.7 17.4 23.3 10.8 33.4 25.  13.9 12.1 24.1 30.1 20.5 13.3\n 15.4 22.6 12.5 29.6 50.  29.8 21.4 19.2 23.7 18.6 20.8 32.4 13.8 22.\n 15.6 23.7 23.9 18.  17.5 14.1 20.5].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_test_hat = np.zeros(y_test.shape)\n",
    "\n",
    "nb_trees = 100\n",
    "\n",
    "for i in range(nb_trees):\n",
    "    dt = tree.DecisionTreeRegressor()\n",
    "    dt.fit(X_train, y_train)\n",
    "    y_test_hat += dt.predict(X_test)\n",
    "    \n",
    "y_test_hat /= nb_trees\n",
    "\n",
    "mse = mean_squared_error(y_test_hat, y_test)\n",
    "print(mse, 3)\n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amlfall23",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
